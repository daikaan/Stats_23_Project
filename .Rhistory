lda_1 <- lda(Attrition_Flag ~ Customer_Age + Is_Female + Dependent_count
+ Marital_Status + Income_Category + Total_Relationship_Count + Months_Inactive_12_mon + Contacts_Count_12_mon + log_Credit_Limit
+ Total_Revolving_Bal + log_Total_Amt_Chng_Q4_Q1 + log_Total_Trans_Amt + Total_Trans_Ct + log_Total_Ct_Chng_Q4_Q1 + Avg_Utilization_Ratio
+ Customer_Age:log_Total_Amt_Chng_Q4_Q1 + Dependent_count:log_Total_Amt_Chng_Q4_Q1 + log_Total_Amt_Chng_Q4_Q1:log_Total_Trans_Amt
+ log_Total_Amt_Chng_Q4_Q1:Total_Trans_Ct + log_Credit_Limit:Total_Revolving_Bal + Total_Revolving_Bal:Avg_Utilization_Ratio
+ log_Credit_Limit:Avg_Utilization_Ratio + Is_Female:log_Total_Ct_Chng_Q4_Q1 + Customer_Age:Marital_Status , data = train, family = "binomial")
lda_1
lda_1_predict <- predict(lda_1,test,type = "response")
lda_predict_1 <- lda_1_predict$posterior
pred_1 <- ifelse(lda_predict_1[,2] >= Threshold1 , 1,0)
pred_2 <- ifelse(lda_predict_1[,2] >= Threshold2 , 1,0)
pred_3 <- ifelse(lda_predict_1[,2] >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1 <- table(test$Attrition_Flag,pred_1)
c_mat_2 <- table(test$Attrition_Flag,pred_2)
c_mat_3 <- table(test$Attrition_Flag,pred_3)
c_mat_1
c_mat_2
c_mat_3
#Accuracy
mean(pred_1==test$Attrition_Flag)*100
mean(pred_2==test$Attrition_Flag)*100
mean(pred_3==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1 <- c_mat_1[1,1]/sum(c_mat_1[1,])
Spec_2 <- c_mat_2[1,1]/sum(c_mat_2[1,])
Spec_3 <- c_mat_3[1,1]/sum(c_mat_3[1,])
Spec_1
Spec_2
Spec_3
#Precision / Positive Predicted Value
Prec_1 <- c_mat_1[2,2]/sum(c_mat_1[,2])
Prec_2 <- c_mat_2[2,2]/sum(c_mat_2[,2])
Prec_3 <- c_mat_3[2,2]/sum(c_mat_3[,2])
Prec_1
Prec_2
Prec_3
#Recall / True Positive Rate / Sensitivity
Rec_1 <- c_mat_1[2,2]/sum(c_mat_1[2,])
Rec_2 <- c_mat_2[2,2]/sum(c_mat_2[2,])
Rec_3 <- c_mat_3[2,2]/sum(c_mat_3[2,])
Rec_1
Rec_2
Rec_3
#F1 Score
F1_1 <- 2 * (Prec_1 * Rec_1)/(Prec_1 + Rec_1)
F1_2 <- 2 * (Prec_2 * Rec_2)/(Prec_2 + Rec_2)
F1_3 <- 2 * (Prec_3 * Rec_3)/(Prec_3 + Rec_3)
F1_1
F1_2
F1_3
#LDA Balanced
#Thresholds
Threshold1 <- 0.6
Threshold2 <- 0.7
Threshold3 <- 0.8
#We still try the LDA model
lda_2 <- lda(Attrition_Flag ~  Customer_Age + Is_Female + Dependent_count + Education_Level
+ Marital_Status + Income_Category + Total_Relationship_Count + Months_Inactive_12_mon + Contacts_Count_12_mon + Total_Revolving_Bal + log_Avg_Open_To_Buy
+ log_Total_Amt_Chng_Q4_Q1 + log_Total_Trans_Amt + Total_Trans_Ct + log_Total_Ct_Chng_Q4_Q1 + Avg_Utilization_Ratio + Customer_Age:log_Total_Amt_Chng_Q4_Q1
+ Dependent_count:log_Total_Amt_Chng_Q4_Q1 + log_Total_Amt_Chng_Q4_Q1:log_Total_Trans_Amt + Total_Revolving_Bal:log_Avg_Open_To_Buy
+ Total_Revolving_Bal:Avg_Utilization_Ratio + log_Avg_Open_To_Buy:Avg_Utilization_Ratio + Is_Female:log_Total_Ct_Chng_Q4_Q1
+ Customer_Age:Marital_Status , data = train_bal, family = "binomial")
lda_2
lda_2_predict <- predict(lda_2,test,type = "response")
lda_predict_2 <- lda_2_predict$posterior
pred_1 <- ifelse(lda_predict_2[,2] >= Threshold1 , 1,0)
pred_2 <- ifelse(lda_predict_2[,2] >= Threshold2 , 1,0)
pred_3 <- ifelse(lda_predict_2[,2] >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1 <- table(test$Attrition_Flag,pred_1)
c_mat_2 <- table(test$Attrition_Flag,pred_2)
c_mat_3 <- table(test$Attrition_Flag,pred_3)
c_mat_1
c_mat_2
c_mat_3
#Accuracy
mean(pred_1==test$Attrition_Flag)*100
mean(pred_2==test$Attrition_Flag)*100
mean(pred_3==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1 <- c_mat_1[1,1]/sum(c_mat_1[1,])
Spec_2 <- c_mat_2[1,1]/sum(c_mat_2[1,])
Spec_3 <- c_mat_3[1,1]/sum(c_mat_3[1,])
Spec_1
Spec_2
Spec_3
#Precision / Positive Predicted Value
Prec_1 <- c_mat_1[2,2]/sum(c_mat_1[,2])
Prec_2 <- c_mat_2[2,2]/sum(c_mat_2[,2])
Prec_3 <- c_mat_3[2,2]/sum(c_mat_3[,2])
Prec_1
Prec_2
Prec_3
#Recall / True Positive Rate / Sensitivity
Rec_1 <- c_mat_1[2,2]/sum(c_mat_1[2,])
Rec_2 <- c_mat_2[2,2]/sum(c_mat_2[2,])
Rec_3 <- c_mat_3[2,2]/sum(c_mat_3[2,])
Rec_1
Rec_2
Rec_3
#F1 Score
F1_1 <- 2 * (Prec_1 * Rec_1)/(Prec_1 + Rec_1)
F1_2 <- 2 * (Prec_2 * Rec_2)/(Prec_2 + Rec_2)
F1_3 <- 2 * (Prec_3 * Rec_3)/(Prec_3 + Rec_3)
F1_1
F1_2
F1_3
#ROC curves
roc_lda <- roc(test$Attrition_Flag ~ lda_predict_1[,2])
roc_lda_bal <- roc(test$Attrition_Flag ~ lda_predict_2[,2])
AUC_lda <- auc(roc_lda)
AUC_lda_bal <- auc(roc_lda_bal)
plot(roc_lda, col = "black",print.auc = TRUE, auc.polygon = TRUE, max.auc.polygon = TRUE, lwd=2,print.auc.x = 0.5,print.auc.y = 0.5)
plot(roc_lda_bal,add = TRUE,col = "blue", print.auc = TRUE, lwd=2, print.auc.x = 0.5,print.auc.y = 0.43)
#Best thresholds and Best Sensitivity and Specificity
Best_Treshold_lda <- coords(roc_lda,"best",best.method = "closest.topleft")$threshold
Best_pred_lda <- ifelse(lda_predict_1[,2] >= Best_Treshold_lda , 1,0)
Best_c_mat <- table(test$Attrition_Flag,Best_pred_lda)
Best_Spec_lda <- Best_c_mat[1,1]/sum(Best_c_mat[1,])
Best_Sens_lda <- Best_c_mat[2,2]/sum(Best_c_mat[2,])
Best_Treshold_lda_bal <- coords(roc_lda_bal,"best",best.method = "closest.topleft")$threshold
Best_pred_lda_bal <- ifelse(lda_predict_2[,2] >= Best_Treshold_lda_bal , 1,0)
Best_c_mat <- table(test$Attrition_Flag,Best_pred_lda_bal)
Best_Spec_lda_bal <- Best_c_mat[1,1]/sum(Best_c_mat[1,])
Best_Sens_lda_bal <- Best_c_mat[2,2]/sum(Best_c_mat[2,])
#Table to show them
Table_mat <-  matrix(c(Best_Treshold_lda,Best_Spec_lda,Best_Sens_lda,Best_Treshold_lda_bal,Best_Spec_lda_bal,Best_Sens_lda_bal), ncol=3, byrow=TRUE)
colnames(Table_mat) <- c("Threshold","Specificity","Sensitivity")
rownames(Table_mat) <- c("Unbalanced","Balanced")
Tab <- as.table(Table_mat)
show(Tab)
#We still try the LDA model
lda_2 <- lda(Attrition_Flag ~  Customer_Age + Is_Female + Dependent_count + Education_Level
+ Marital_Status + Income_Category + Total_Relationship_Count + Months_Inactive_12_mon + Contacts_Count_12_mon + Total_Revolving_Bal + log_Avg_Open_To_Buy
+ log_Total_Amt_Chng_Q4_Q1 + log_Total_Trans_Amt + Total_Trans_Ct + log_Total_Ct_Chng_Q4_Q1 + Avg_Utilization_Ratio s , data = train_bal, family = "binomial")
#We still try the LDA model
lda_2 <- lda(Attrition_Flag ~  Customer_Age + Is_Female + Dependent_count + Education_Level
+ Marital_Status + Income_Category + Total_Relationship_Count + Months_Inactive_12_mon + Contacts_Count_12_mon + Total_Revolving_Bal + log_Avg_Open_To_Buy
+ log_Total_Amt_Chng_Q4_Q1 + log_Total_Trans_Amt + Total_Trans_Ct + log_Total_Ct_Chng_Q4_Q1 + Avg_Utilization_Ratio  , data = train_bal, family = "binomial")
lda_2
lda_2_predict <- predict(lda_2,test,type = "response")
lda_predict_2 <- lda_2_predict$posterior
pred_1 <- ifelse(lda_predict_2[,2] >= Threshold1 , 1,0)
pred_2 <- ifelse(lda_predict_2[,2] >= Threshold2 , 1,0)
pred_3 <- ifelse(lda_predict_2[,2] >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1 <- table(test$Attrition_Flag,pred_1)
c_mat_2 <- table(test$Attrition_Flag,pred_2)
c_mat_3 <- table(test$Attrition_Flag,pred_3)
c_mat_1
c_mat_2
c_mat_3
#Accuracy
mean(pred_1==test$Attrition_Flag)*100
mean(pred_2==test$Attrition_Flag)*100
mean(pred_3==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1 <- c_mat_1[1,1]/sum(c_mat_1[1,])
Spec_2 <- c_mat_2[1,1]/sum(c_mat_2[1,])
Spec_3 <- c_mat_3[1,1]/sum(c_mat_3[1,])
Spec_1
Spec_2
Spec_3
#Precision / Positive Predicted Value
Prec_1 <- c_mat_1[2,2]/sum(c_mat_1[,2])
Prec_2 <- c_mat_2[2,2]/sum(c_mat_2[,2])
Prec_3 <- c_mat_3[2,2]/sum(c_mat_3[,2])
Prec_1
Prec_2
Prec_3
#Recall / True Positive Rate / Sensitivity
Rec_1 <- c_mat_1[2,2]/sum(c_mat_1[2,])
Rec_2 <- c_mat_2[2,2]/sum(c_mat_2[2,])
Rec_3 <- c_mat_3[2,2]/sum(c_mat_3[2,])
Rec_1
Rec_2
Rec_3
#F1 Score
F1_1 <- 2 * (Prec_1 * Rec_1)/(Prec_1 + Rec_1)
F1_2 <- 2 * (Prec_2 * Rec_2)/(Prec_2 + Rec_2)
F1_3 <- 2 * (Prec_3 * Rec_3)/(Prec_3 + Rec_3)
F1_1
F1_2
F1_3
#ROC curves
roc_lda <- roc(test$Attrition_Flag ~ lda_predict_1[,2])
roc_lda_bal <- roc(test$Attrition_Flag ~ lda_predict_2[,2])
AUC_lda <- auc(roc_lda)
AUC_lda_bal <- auc(roc_lda_bal)
plot(roc_lda, col = "black",print.auc = TRUE, auc.polygon = TRUE, max.auc.polygon = TRUE, lwd=2,print.auc.x = 0.5,print.auc.y = 0.5)
plot(roc_lda_bal,add = TRUE,col = "blue", print.auc = TRUE, lwd=2, print.auc.x = 0.5,print.auc.y = 0.43)
#Best thresholds and Best Sensitivity and Specificity
Best_Treshold_lda <- coords(roc_lda,"best",best.method = "closest.topleft")$threshold
Best_pred_lda <- ifelse(lda_predict_1[,2] >= Best_Treshold_lda , 1,0)
Best_c_mat <- table(test$Attrition_Flag,Best_pred_lda)
Best_Spec_lda <- Best_c_mat[1,1]/sum(Best_c_mat[1,])
Best_Sens_lda <- Best_c_mat[2,2]/sum(Best_c_mat[2,])
Best_Treshold_lda_bal <- coords(roc_lda_bal,"best",best.method = "closest.topleft")$threshold
Best_pred_lda_bal <- ifelse(lda_predict_2[,2] >= Best_Treshold_lda_bal , 1,0)
Best_c_mat <- table(test$Attrition_Flag,Best_pred_lda_bal)
Best_Spec_lda_bal <- Best_c_mat[1,1]/sum(Best_c_mat[1,])
Best_Sens_lda_bal <- Best_c_mat[2,2]/sum(Best_c_mat[2,])
#Table to show them
Table_mat <-  matrix(c(Best_Treshold_lda,Best_Spec_lda,Best_Sens_lda,Best_Treshold_lda_bal,Best_Spec_lda_bal,Best_Sens_lda_bal), ncol=3, byrow=TRUE)
colnames(Table_mat) <- c("Threshold","Specificity","Sensitivity")
rownames(Table_mat) <- c("Unbalanced","Balanced")
Tab <- as.table(Table_mat)
show(Tab)
#QDA
glm_1 <- glm(data = train,Attrition_Flag~ .,family = "binomial")
summary(glm_1)
#Thresholds
Threshold1 <- 0.3
Threshold2 <- 0.4
Threshold3 <- 0.5
pred_glm_i <- predict(glm_1,test,type="response")
pred_1_i <- ifelse(pred_glm_i >= Threshold1 , 1,0)
pred_2_i <- ifelse(pred_glm_i >= Threshold2 , 1,0)
pred_3_i <- ifelse(pred_glm_i >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1_i <- table(test$Attrition_Flag,pred_1_i)
c_mat_2_i <- table(test$Attrition_Flag,pred_2_i)
c_mat_3_i <- table(test$Attrition_Flag,pred_3_i)
c_mat_1_i
c_mat_2_i
c_mat_3_i
#Accuracy
mean(pred_1_i==test$Attrition_Flag)*100
mean(pred_2_i==test$Attrition_Flag)*100
mean(pred_3_i==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1_i <- c_mat_1_i[1,1]/sum(c_mat_1_i[1,])
Spec_2_i <- c_mat_2_i[1,1]/sum(c_mat_2_i[1,])
Spec_3_i <- c_mat_3_i[1,1]/sum(c_mat_3_i[1,])
Spec_1_i
Spec_2_i
Spec_3_i
#Precision / Positive Predicted Value
Prec_1_i <- c_mat_1_i[2,2]/sum(c_mat_1_i[,2])
Prec_2_i <- c_mat_2_i[2,2]/sum(c_mat_2_i[,2])
Prec_3_i <- c_mat_3_i[2,2]/sum(c_mat_3_i[,2])
Prec_1_i
Prec_2_i
Prec_3_i
#Recall / True Positive Rate / Sensitivity
Rec_1_i <- c_mat_1_i[2,2]/sum(c_mat_1_i[2,])
Rec_2_i <- c_mat_2_i[2,2]/sum(c_mat_2_i[2,])
Rec_3_i <- c_mat_3_i[2,2]/sum(c_mat_3_i[2,])
Rec_1_i
Rec_2_i
Rec_3_i
#F1 Score
F1_1_i <- 2 * (Prec_1_i * Rec_1_i)/(Prec_1_i + Rec_1_i)
F1_2_i <- 2 * (Prec_2_i * Rec_2_i)/(Prec_2_i + Rec_2_i)
F1_3_i <- 2 * (Prec_3_i * Rec_3_i)/(Prec_3_i + Rec_3_i)
F1_1_i
F1_2_i
F1_3_i
#VIF
vif(glm_1)
#Update Checking p-values and AIC
glm_2 <- update(glm_1, . ~ . - log_Avg_Open_To_Buy)
summary(glm_2)
vif(glm_2)
glm_3 <- update(glm_2, . ~ . - Months_on_book)
summary(glm_3)
glm_4 <- update(glm_3, . ~ . + log_Total_Amt_Chng_Q4_Q1*Customer_Age + log_Total_Amt_Chng_Q4_Q1*Dependent_count
+ log_Total_Amt_Chng_Q4_Q1*log_Total_Trans_Amt + log_Total_Amt_Chng_Q4_Q1*Total_Trans_Ct)
summary(glm_4)
#Show that there is interaction
interact_plot(glm_4,pred = log_Total_Amt_Chng_Q4_Q1,modx = Customer_Age, outcome.scale = "link")
interact_plot(glm_4,pred = log_Total_Amt_Chng_Q4_Q1,modx = Dependent_count, outcome.scale = "link")
interact_plot(glm_4,pred = log_Total_Amt_Chng_Q4_Q1,modx = log_Total_Trans_Amt, outcome.scale = "link")
interact_plot(glm_4,pred = log_Total_Amt_Chng_Q4_Q1,modx = Total_Trans_Ct, outcome.scale = "link")
glm_5 <- update(glm_4, . ~ . + Total_Revolving_Bal*log_Credit_Limit + Total_Revolving_Bal*Avg_Utilization_Ratio)
summary(glm_5)
#Interaction
interact_plot(glm_5,pred = Total_Revolving_Bal,modx = log_Credit_Limit, outcome.scale = "link")
interact_plot(glm_5,pred = Total_Revolving_Bal,modx = Avg_Utilization_Ratio, outcome.scale = "link")
glm_6 <- update(glm_5, . ~ . + log_Credit_Limit*Avg_Utilization_Ratio)
summary(glm_6)
#Show that there is interaction
interact_plot(glm_6,pred = log_Credit_Limit,modx = Avg_Utilization_Ratio, outcome.scale = "link")
glm_7 <- update(glm_6, . ~ . + log_Total_Ct_Chng_Q4_Q1*Is_Female)
summary(glm_7)
#Interaction
interact_plot(glm_7,pred = log_Total_Ct_Chng_Q4_Q1,modx = Is_Female, outcome.scale = "link")
glm_8 <- update(glm_7, . ~ . - Education_Level)
summary(glm_8)
glm_9 <- update(glm_8, . ~ .+ Customer_Age*Marital_Status)
summary(glm_9)
#Interaction
interact_plot(glm_9,pred = Customer_Age,modx = Marital_Status , outcome.scale = "link")
pred_glm_f <- predict(glm_9,test,type="response")
pred_1_f <- ifelse(pred_glm_f >= Threshold1 , 1,0)
pred_2_f <- ifelse(pred_glm_f >= Threshold2 , 1,0)
pred_3_f <- ifelse(pred_glm_f >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1_f <- table(test$Attrition_Flag,pred_1_f)
c_mat_2_f <- table(test$Attrition_Flag,pred_2_f)
c_mat_3_f <- table(test$Attrition_Flag,pred_3_f)
c_mat_1_f
c_mat_2_f
c_mat_3_f
#Accuracy
mean(pred_1_f==test$Attrition_Flag)*100
mean(pred_2_f==test$Attrition_Flag)*100
mean(pred_3_f==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1_f <- c_mat_1_f[1,1]/sum(c_mat_1_f[1,])
Spec_2_f <- c_mat_2_f[1,1]/sum(c_mat_2_f[1,])
Spec_3_f <- c_mat_3_f[1,1]/sum(c_mat_3_f[1,])
Spec_1_f
Spec_2_f
Spec_3_f
#Precision / Positive Predicted Value
Prec_1_f <- c_mat_1_f[2,2]/sum(c_mat_1_f[,2])
Prec_2_f <- c_mat_2_f[2,2]/sum(c_mat_2_f[,2])
Prec_3_f <- c_mat_3_f[2,2]/sum(c_mat_3_f[,2])
Prec_1_f
Prec_2_f
Prec_3_f
#Recall / True Positive Rate / Sensitivity
Rec_1_f <- c_mat_1_f[2,2]/sum(c_mat_1_f[2,])
Rec_2_f <- c_mat_2_f[2,2]/sum(c_mat_2_f[2,])
Rec_3_f <- c_mat_3_f[2,2]/sum(c_mat_3_f[2,])
Rec_1_f
Rec_2_f
Rec_3_f
#F1 Score
F1_1_f <- 2 * (Prec_1_f * Rec_1_f)/(Prec_1_f + Rec_1_f)
F1_2_f <- 2 * (Prec_2_f * Rec_2_f)/(Prec_2_f + Rec_2_f)
F1_3_f <- 2 * (Prec_3_f * Rec_3_f)/(Prec_3_f + Rec_3_f)
F1_1_f
F1_2_f
F1_3_f
#ROC curves
roc_i <- roc(test$Attrition_Flag ~ pred_glm_i)
roc_f <- roc(test$Attrition_Flag ~ pred_glm_f)
AUC_i <- auc(roc_i)
AUC_f <- auc(roc_f)
plot(roc_i, col = "black",print.auc = TRUE, auc.polygon = TRUE, max.auc.polygon = TRUE, lwd=2,print.auc.x = 0.5,print.auc.y = 0.5)
plot(roc_f,add = TRUE,col = "blue", print.auc = TRUE, lwd=2, print.auc.x = 0.5,print.auc.y = 0.43)
#Best thresholds and Best Sensitivity and Specificity
Best_Treshold_i <- coords(roc_i,"best",best.method = "closest.topleft")$threshold
Best_pred_i <- ifelse(pred_glm_i >= Best_Treshold_i , 1,0)
Best_c_mat_i <- table(test$Attrition_Flag,Best_pred_i)
Best_Spec_i <- Best_c_mat_i[1,1]/sum(Best_c_mat_i[1,])
Best_Sens_i <- Best_c_mat_i[2,2]/sum(Best_c_mat_i[2,])
Best_Treshold_f <- coords(roc_f,"best",best.method = "closest.topleft")$threshold
Best_pred_f <- ifelse(pred_glm_f >= Best_Treshold_f , 1,0)
Best_c_mat_f <- table(test$Attrition_Flag,Best_pred_f)
Best_Spec_f <- Best_c_mat_f[1,1]/sum(Best_c_mat_f[1,])
Best_Sens_f <- Best_c_mat_f[2,2]/sum(Best_c_mat_f[2,])
#Table to show them
Table_mat <-  matrix(c(Best_Treshold_i,Best_Spec_i,Best_Sens_i,Best_Treshold_f,Best_Spec_f,Best_Sens_f), ncol=3, byrow=TRUE)
colnames(Table_mat) <- c("Threshold","Specificity","Sensitivity")
rownames(Table_mat) <- c("Initial model","Final model")
Tab <- as.table(Table_mat)
show(Tab)
#Model with balanced train set
glm_1_bal <- glm(data = train_bal,Attrition_Flag~ .,family = "binomial")
summary(glm_1_bal)
#Thresholds
Threshold1 <- 0.6
Threshold2 <- 0.7
Threshold3 <- 0.8
pred_glm_bal_i <- predict(glm_1_bal,test,type="response")
pred_1_i <- ifelse(pred_glm_bal_i >= Threshold1 , 1,0)
pred_2_i <- ifelse(pred_glm_bal_i >= Threshold2 , 1,0)
pred_3_i <- ifelse(pred_glm_bal_i >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1_i <- table(test$Attrition_Flag,pred_1_i)
c_mat_2_i <- table(test$Attrition_Flag,pred_2_i)
c_mat_3_i <- table(test$Attrition_Flag,pred_3_i)
c_mat_1_i
c_mat_2_i
c_mat_3_i
#Accuracy
mean(pred_1_i==test$Attrition_Flag)*100
mean(pred_2_i==test$Attrition_Flag)*100
mean(pred_3_i==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1_i <- c_mat_1_i[1,1]/sum(c_mat_1_i[1,])
Spec_2_i <- c_mat_2_i[1,1]/sum(c_mat_2_i[1,])
Spec_3_i <- c_mat_3_i[1,1]/sum(c_mat_3_i[1,])
Spec_1_i
Spec_2_i
Spec_3_i
#Precision / Positive Predicted Value
Prec_1_i <- c_mat_1_i[2,2]/sum(c_mat_1_i[,2])
Prec_2_i <- c_mat_2_i[2,2]/sum(c_mat_2_i[,2])
Prec_3_i <- c_mat_3_i[2,2]/sum(c_mat_3_i[,2])
Prec_1_i
Prec_2_i
Prec_3_i
#Recall / True Positive Rate / Sensitivity
Rec_1_i <- c_mat_1_i[2,2]/sum(c_mat_1_i[2,])
Rec_2_i <- c_mat_2_i[2,2]/sum(c_mat_2_i[2,])
Rec_3_i <- c_mat_3_i[2,2]/sum(c_mat_3_i[2,])
Rec_1_i
Rec_2_i
Rec_3_i
#F1 Score
F1_1_i <- 2 * (Prec_1_i * Rec_1_i)/(Prec_1_i + Rec_1_i)
F1_2_i <- 2 * (Prec_2_i * Rec_2_i)/(Prec_2_i + Rec_2_i)
F1_3_i <- 2 * (Prec_3_i * Rec_3_i)/(Prec_3_i + Rec_3_i)
F1_1_i
F1_2_i
F1_3_i
#VIF
vif(glm_1)
#Update Checking p-values and AIC
glm_2_bal <- update(glm_1_bal, . ~ . - log_Credit_Limit)
summary(glm_2_bal)
vif(glm_2_bal)
glm_3_bal <- update(glm_2_bal, . ~ . - Months_on_book)
summary(glm_3_bal)
glm_4_bal <- update(glm_3_bal, . ~ . + log_Total_Amt_Chng_Q4_Q1*Customer_Age + log_Total_Amt_Chng_Q4_Q1*Dependent_count
+ log_Total_Amt_Chng_Q4_Q1*log_Total_Trans_Amt)
summary(glm_4_bal)
#Show that there is interaction
interact_plot(glm_4_bal,pred = log_Total_Amt_Chng_Q4_Q1,modx = Customer_Age, outcome.scale = "link")
interact_plot(glm_4_bal,pred = log_Total_Amt_Chng_Q4_Q1,modx = Dependent_count, outcome.scale = "link")
interact_plot(glm_4_bal,pred = log_Total_Amt_Chng_Q4_Q1,modx = log_Total_Trans_Amt, outcome.scale = "link")
glm_5_bal <- update(glm_4_bal, . ~ . + Total_Revolving_Bal*log_Avg_Open_To_Buy + Total_Revolving_Bal*Avg_Utilization_Ratio)
summary(glm_5_bal)
#Interaction
interact_plot(glm_5_bal,pred = Total_Revolving_Bal,modx = log_Avg_Open_To_Buy, outcome.scale = "link")
interact_plot(glm_5_bal,pred = Avg_Utilization_Ratio,modx = Total_Revolving_Bal, outcome.scale = "link")
glm_6_bal <- update(glm_5_bal, . ~ . + log_Avg_Open_To_Buy*Avg_Utilization_Ratio)
summary(glm_6_bal)
#Show that there is interaction
interact_plot(glm_6_bal,pred = Avg_Utilization_Ratio,modx = log_Avg_Open_To_Buy, outcome.scale = "link")
glm_7_bal <- update(glm_6_bal, . ~ . + log_Total_Ct_Chng_Q4_Q1*Is_Female)
summary(glm_7_bal)
#Interaction
interact_plot(glm_7_bal,pred = log_Total_Ct_Chng_Q4_Q1,modx = Is_Female, outcome.scale = "link")
glm_8_bal <- update(glm_7_bal, . ~ . + Customer_Age*Marital_Status)
summary(glm_8_bal)
#Interaction
interact_plot(glm_8_bal,pred = Customer_Age,modx = Marital_Status, outcome.scale = "link")
#Interaction
interact_plot(glm_8_bal,pred = Avg_Utilization_Ratio, modx = Total_Revolving_Bal, outcome.scale = "link")
pred_glm_bal_f <- predict(glm_8_bal,test,type="response")
pred_1_f <- ifelse(pred_glm_bal_f >= Threshold1 , 1,0)
pred_2_f <- ifelse(pred_glm_bal_f >= Threshold2 , 1,0)
pred_3_f <- ifelse(pred_glm_bal_f >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1_f <- table(test$Attrition_Flag,pred_1_f)
c_mat_2_f <- table(test$Attrition_Flag,pred_2_f)
c_mat_3_f <- table(test$Attrition_Flag,pred_3_f)
c_mat_1_f
c_mat_2_f
c_mat_3_f
#Accuracy
mean(pred_1_f==test$Attrition_Flag)*100
mean(pred_2_f==test$Attrition_Flag)*100
mean(pred_3_f==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1_f <- c_mat_1_f[1,1]/sum(c_mat_1_f[1,])
Spec_2_f <- c_mat_2_f[1,1]/sum(c_mat_2_f[1,])
Spec_3_f <- c_mat_3_f[1,1]/sum(c_mat_3_f[1,])
Spec_1_f
Spec_2_f
Spec_3_f
#Precision / Positive Predicted Value
Prec_1_f <- c_mat_1_f[2,2]/sum(c_mat_1_f[,2])
Prec_2_f <- c_mat_2_f[2,2]/sum(c_mat_2_f[,2])
Prec_3_f <- c_mat_3_f[2,2]/sum(c_mat_3_f[,2])
Prec_1_f
Prec_2_f
Prec_3_f
#Recall / True Positive Rate / Sensitivity
Rec_1_f <- c_mat_1_f[2,2]/sum(c_mat_1_f[2,])
Rec_2_f <- c_mat_2_f[2,2]/sum(c_mat_2_f[2,])
Rec_3_f <- c_mat_3_f[2,2]/sum(c_mat_3_f[2,])
Rec_1_f
Rec_2_f
Rec_3_f
#F1 Score
F1_1_f <- 2 * (Prec_1_f * Rec_1_f)/(Prec_1_f + Rec_1_f)
F1_2_f <- 2 * (Prec_2_f * Rec_2_f)/(Prec_2_f + Rec_2_f)
F1_3_f <- 2 * (Prec_3_f * Rec_3_f)/(Prec_3_f + Rec_3_f)
F1_1_f
F1_2_f
F1_3_f
#ROC curves
roc_bal_i <- roc(test$Attrition_Flag ~ pred_glm_bal_i)
roc_bal_f <- roc(test$Attrition_Flag ~ pred_glm_bal_f)
AUC_bal_i <- auc(roc_i)
AUC_bal_f <- auc(roc_f)
plot(roc_bal_i, col = "black",print.auc = TRUE, auc.polygon = TRUE, max.auc.polygon = TRUE, lwd=2,print.auc.x = 0.5,print.auc.y = 0.5)
plot(roc_bal_f,add = TRUE,col = "blue", print.auc = TRUE, lwd=2, print.auc.x = 0.5,print.auc.y = 0.43)
#Best thresholds and Best Sensitivity and Specificity
Best_Treshold_bal_i <- coords(roc_bal_i,"best",best.method = "closest.topleft")$threshold
Best_pred_bal_i <- ifelse(pred_glm_bal_i >= Best_Treshold_bal_i , 1,0)
Best_c_mat_i <- table(test$Attrition_Flag,Best_pred_bal_i)
Best_Spec_bal_i <- Best_c_mat_i[1,1]/sum(Best_c_mat_i[1,])
Best_Sens_bal_i <- Best_c_mat_i[2,2]/sum(Best_c_mat_i[2,])
Best_Treshold_bal_f <- coords(roc_bal_f,"best",best.method = "closest.topleft")$threshold
Best_pred_bal_f <- ifelse(pred_glm_bal_f >= Best_Treshold_bal_f , 1,0)
Best_c_mat_f <- table(test$Attrition_Flag,Best_pred_bal_f)
Best_Spec_bal_f <- Best_c_mat_f[1,1]/sum(Best_c_mat_f[1,])
Best_Sens_bal_f <- Best_c_mat_f[2,2]/sum(Best_c_mat_f[2,])
#Table to show them
Table_mat <-  matrix(c(Best_Treshold_bal_i,Best_Spec_bal_i,Best_Sens_bal_i,Best_Treshold_bal_f,Best_Spec_bal_f,Best_Sens_bal_f), ncol=3, byrow=TRUE)
colnames(Table_mat) <- c("Threshold","Specificity","Sensitivity")
rownames(Table_mat) <- c("Initial model","Final model")
Tab <- as.table(Table_mat)
show(Tab)
