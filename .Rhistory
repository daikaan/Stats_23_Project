glm_5_bal <- update(glm_4_bal, . ~ . + Total_Ct_Chng_Q4_Q1*Dependent_count
+ Total_Ct_Chng_Q4_Q1*Is_Female)
glm_6_bal <- update(glm_5_bal, . ~ . - Credit_Limit)
glm_7_bal <- update(glm_6_bal, . ~ . + Customer_Age*Marital_Status)
summary(glm_7_bal)
AIC(glm_1_bal,glm_2_bal,glm_3_bal,glm_4_bal,glm_5_bal,glm_6_bal,glm_7_bal)
#Threshold
Threshold <- 0.8
pred_glm_f_bal <- predict(glm_7_bal,test,type="response")
pred_f_bal <- ifelse(pred_glm_f_bal >= Threshold , 1,0)
#Confusion matrix
c_mat_f_bal <- table(test$Attrition_Flag,pred_f_bal)
#Accuracy
mean(pred_f_bal==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_f_bal <- c_mat_f_bal[1,1]/sum(c_mat_f_bal[1,])
Spec_f_bal
#Precision / Positive Predicted Value
Prec_f_bal <- c_mat_f_bal[2,2]/sum(c_mat_f_bal[,2])
Prec_f_bal
#Recall / True Positive Rate / Sensitivity
Rec_f_bal <- c_mat_f_bal[2,2]/sum(c_mat_f_bal[2,])
Rec_f_bal
#F1 Score
F1_f_bal <- 2 * (Prec_f_bal * Rec_f_bal)/(Prec_f_bal + Rec_f_bal)
F1_f_bal
#ROC curves
roc_i_bal <- roc(test$Attrition_Flag ~ pred_glm_i_bal)
roc_f_bal <- roc(test$Attrition_Flag ~ pred_glm_f_bal)
plot(roc_i_bal, col = "black",print.auc = FALSE, auc.polygon = TRUE,
max.auc.polygon = TRUE, lwd=2)
plot(roc_f_bal,add = TRUE,col = "blue", print.auc = FALSE, lwd=2)
text(0.3, 0.45, paste("AUC for glm_1_bal:", round(roc_i_bal$auc, 3)), col = "black")
text(0.3, 0.38, paste("AUC for glm_7_bal:", round(roc_f_bal$auc, 3)), col = "blue")
# We can see that the continuous predictor variables don't follow a normal
# distribution on both classes
apply(train[train$Attrition_Flag == 1,][17:18],2,shapiro.test )
apply(train[train$Attrition_Flag == 0,][17:18],2,shapiro.test )
lda_u <- lda(Attrition_Flag ~ Customer_Age + Is_Female + Dependent_count
+ Marital_Status + Income_Category + Total_Relationship_Count
+ Months_Inactive_12_mon + Contacts_Count_12_mon + Credit_Limit
+ Total_Revolving_Bal + Total_Amt_Chng_Q4_Q1
+ Total_Trans_Amt + Total_Trans_Ct + Total_Ct_Chng_Q4_Q1
+ Avg_Utilization_Ratio + Total_Revolving_Bal:Avg_Utilization_Ratio
+ Total_Trans_Amt:Total_Trans_Ct
+ Total_Amt_Chng_Q4_Q1:Total_Trans_Amt
+ Is_Female:Total_Trans_Amt
+ Total_Relationship_Count:Total_Trans_Amt
+ Dependent_count:Total_Ct_Chng_Q4_Q1
+ Is_Female:Total_Ct_Chng_Q4_Q1
+ Customer_Age:Marital_Status ,
data = train, family = "binomial")
lda_u
#Threshold
Threshold <- 0.4
lda_u_predict <- predict(lda_u,test,type = "response")
lda_predict_u <- lda_u_predict$posterior
pred_lda_u <- ifelse(lda_predict_u[,2] >= Threshold , 1,0)
#Confusion matrix
c_mat_lda_u <- table(test$Attrition_Flag,pred_lda_u)
#Accuracy
mean(pred_lda_u==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_lda_u <- c_mat_lda_u[1,1]/sum(c_mat_lda_u[1,])
Spec_lda_u
#Precision / Positive Predicted Value
Prec_lda_u <- c_mat_lda_u[2,2]/sum(c_mat_lda_u[,2])
Prec_lda_u
#Recall / True Positive Rate / Sensitivity
Rec_lda_u <- c_mat_lda_u[2,2]/sum(c_mat_lda_u[2,])
Rec_lda_u
#F1 Score
F1_lda_u <- 2 * (Prec_lda_u * Rec_lda_u)/(Prec_lda_u + Rec_lda_u)
F1_lda_u
# x indicates the linear combinations of the variables obtained by the model
# class indicates the two classes Existing and Attriting Customers.
ldahist(lda_u_predict$x[,1], g = lda_u_predict$class , col = 2)
lda_b <- lda(Attrition_Flag ~ Customer_Age + Is_Female + Dependent_count
+ Education_Level + Marital_Status + Income_Category
+ Total_Relationship_Count + Months_Inactive_12_mon
+ Contacts_Count_12_mon + Total_Revolving_Bal
+ Total_Amt_Chng_Q4_Q1 + Total_Trans_Amt + Total_Trans_Ct
+ Total_Ct_Chng_Q4_Q1  + Avg_Utilization_Ratio
+ Customer_Age:Total_Amt_Chng_Q4_Q1
+ Total_Revolving_Bal:Avg_Utilization_Ratio
+ Total_Trans_Amt:Total_Trans_Ct
+ Total_Amt_Chng_Q4_Q1:Total_Trans_Amt
+ Is_Female:Total_Trans_Amt
+ Total_Relationship_Count:Total_Trans_Amt
+ Dependent_count:Total_Ct_Chng_Q4_Q1
+ Is_Female:Total_Ct_Chng_Q4_Q1
+ Customer_Age:Marital_Status ,
data = train_bal, family = "binomial")
lda_b
#Threshold
Threshold <- 0.8
lda_b_predict <- predict(lda_b,test,type = "response")
lda_predict_b <- lda_b_predict$posterior
pred_lda_b <- ifelse(lda_predict_b[,2] >= Threshold , 1,0)
#Confusion matrix
c_mat_lda_b <- table(test$Attrition_Flag,pred_lda_b)
#Accuracy
mean(pred_lda_b==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_lda_b <- c_mat_lda_b[1,1]/sum(c_mat_lda_b[1,])
Spec_lda_b
#Precision / Positive Predicted Value
Prec_lda_b <- c_mat_lda_b[2,2]/sum(c_mat_lda_b[,2])
Prec_lda_b
#Recall / True Positive Rate / Sensitivity
Rec_lda_b <- c_mat_lda_b[2,2]/sum(c_mat_lda_b[2,])
Rec_lda_b
#F1 Score
F1_lda_b <- 2 * (Prec_lda_b * Rec_lda_b)/(Prec_lda_b + Rec_lda_b)
F1_lda_b
# x indicates the linear combinations of the variables obtained by the model
# class indicates the two classes Existing and Attriting Customers.
ldahist(lda_b_predict$x[,1], g = lda_b_predict$class , col = 2)
#ROC curves
roc_lda_u <- roc(test$Attrition_Flag ~ lda_predict_u[,2])
roc_lda_b <- roc(test$Attrition_Flag ~ lda_predict_b[,2])
plot(roc_lda_u, col = "black",print.auc = FALSE, auc.polygon = TRUE,
max.auc.polygon = TRUE, lwd=2)
plot(roc_lda_b,add = TRUE,col = "blue", print.auc = FALSE, lwd=2)
text(0.3, 0.45, paste("AUC for lda_u:", round(roc_lda_u$auc, 3)), col = "black")
text(0.3, 0.38, paste("AUC for lda_b:", round(roc_lda_b$auc, 3)), col = "blue")
qda_u <- qda(Attrition_Flag ~ Customer_Age + Is_Female + Dependent_count
+ Marital_Status + Income_Category + Total_Relationship_Count
+ Months_Inactive_12_mon + Contacts_Count_12_mon + Credit_Limit
+ Total_Revolving_Bal + Total_Amt_Chng_Q4_Q1
+ Total_Trans_Amt + Total_Trans_Ct + Total_Ct_Chng_Q4_Q1
+ Avg_Utilization_Ratio + Total_Revolving_Bal:Avg_Utilization_Ratio
+ Total_Trans_Amt:Total_Trans_Ct
+ Total_Amt_Chng_Q4_Q1:Total_Trans_Amt
+ Is_Female:Total_Trans_Amt
+ Total_Relationship_Count:Total_Trans_Amt
+ Dependent_count:Total_Ct_Chng_Q4_Q1
+ Is_Female:Total_Ct_Chng_Q4_Q1
+ Customer_Age:Marital_Status ,
data = train, family = "binomial")
qda_u
#Threshold
Threshold <- 0.9
qda_u_predict <- predict(qda_u,test,type = "response")
qda_predict_u <- qda_u_predict$posterior
pred_qda_u <- ifelse(qda_predict_u[,2] >= Threshold , 1,0)
#Confusion matrix
c_mat_qda_u <- table(test$Attrition_Flag,pred_qda_u)
#Accuracy
mean(pred_qda_u==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_qda_u <- c_mat_qda_u[1,1]/sum(c_mat_qda_u[1,])
Spec_qda_u
#Precision / Positive Predicted Value
Prec_qda_u <- c_mat_qda_u[2,2]/sum(c_mat_qda_u[,2])
Prec_qda_u
#Recall / True Positive Rate / Sensitivity
Rec_qda_u <- c_mat_qda_u[2,2]/sum(c_mat_qda_u[2,])
Rec_qda_u
#F1 Score
F1_qda_u <- 2 * (Prec_qda_u * Rec_qda_u)/(Prec_qda_u + Rec_qda_u)
F1_qda_u
qda_b <- qda(Attrition_Flag ~ Customer_Age + Is_Female + Dependent_count
+ Education_Level + Marital_Status + Income_Category
+ Total_Relationship_Count + Months_Inactive_12_mon
+ Contacts_Count_12_mon + Total_Revolving_Bal
+ Total_Amt_Chng_Q4_Q1 + Total_Trans_Amt + Total_Trans_Ct
+ Total_Ct_Chng_Q4_Q1  + Avg_Utilization_Ratio
+ Customer_Age:Total_Amt_Chng_Q4_Q1
+ Total_Revolving_Bal:Avg_Utilization_Ratio
+ Total_Trans_Amt:Total_Trans_Ct
+ Total_Amt_Chng_Q4_Q1:Total_Trans_Amt
+ Is_Female:Total_Trans_Amt
+ Total_Relationship_Count:Total_Trans_Amt
+ Dependent_count:Total_Ct_Chng_Q4_Q1
+ Is_Female:Total_Ct_Chng_Q4_Q1
+ Customer_Age:Marital_Status ,
data = train_bal, family = "binomial")
qda_b
#Threshold
Threshold <- 0.9
qda_b_predict <- predict(qda_b,test,type = "response")
qda_predict_b <- qda_b_predict$posterior
pred_qda_b <- ifelse(qda_predict_b[,2] >= Threshold , 1,0)
#Confusion matrix
c_mat_qda_b <- table(test$Attrition_Flag,pred_qda_b)
#Accuracy
mean(pred_qda_b==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_qda_b <- c_mat_qda_b[1,1]/sum(c_mat_qda_b[1,])
Spec_qda_b
#Precision / Positive Predicted Value
Prec_qda_b <- c_mat_qda_b[2,2]/sum(c_mat_qda_b[,2])
Prec_qda_b
#Recall / True Positive Rate / Sensitivity
Rec_qda_b <- c_mat_qda_b[2,2]/sum(c_mat_qda_b[2,])
Rec_qda_b
#F1 Score
F1_qda_b <- 2 * (Prec_qda_b * Rec_qda_b)/(Prec_qda_b + Rec_qda_b)
F1_qda_b
#ROC curves
roc_qda_u <- roc(test$Attrition_Flag ~ qda_predict_u[,2])
roc_qda_b <- roc(test$Attrition_Flag ~ qda_predict_b[,2])
plot(roc_qda_u, col = "black",print.auc = FALSE, auc.polygon = TRUE,
max.auc.polygon = TRUE, lwd=2)
plot(roc_qda_b,add = TRUE,col = "blue", print.auc = FALSE, lwd=2)
text(0.3, 0.45, paste("AUC for qda_u:", round(roc_qda_u$auc, 3)), col = "black")
text(0.3, 0.38, paste("AUC for qda_b:", round(roc_qda_b$auc, 3)), col = "blue")
#Creation of train and test set with interactions
train_int <- data.frame(train)
train_int$Total_Revolving_Bal_Avg_Utilization_Ratio <-
train$Total_Revolving_Bal * train$Avg_Utilization_Ratio
train_int$Total_Trans_Amt_Total_Trans_Ct <-
train$Total_Trans_Amt * train$Total_Trans_Ct
train_int$Total_Trans_Amt_Total_Amt_Chng_Q4_Q1 <-
train$Total_Trans_Amt * train$Total_Amt_Chng_Q4_Q1
train_int$Total_Trans_Amt_Is_Female <-
train$Total_Trans_Amt * train$Is_Female
train_int$Total_Trans_Amt_Total_Relationship_Count <-
train$Total_Trans_Amt * train$Total_Relationship_Count
train_int$Dependant_count_Total_Ct_Chng_Q4_Q1 <-
train$Dependent_count * train$Total_Ct_Chng_Q4_Q1
train_int$Is_Female_Total_Ct_Chng_Q4_Q1 <-
train$Is_Female * train$Total_Ct_Chng_Q4_Q1
train_int$Customer_Age_Marital_Status <-
train$Customer_Age * train$Marital_Status
test_int <- data.frame(test)
test_int$Total_Revolving_Bal_Avg_Utilization_Ratio <-
test$Total_Revolving_Bal * test$Avg_Utilization_Ratio
test_int$Total_Trans_Amt_Total_Trans_Ct <-
test$Total_Trans_Amt * test$Total_Trans_Ct
test_int$Total_Trans_Amt_Total_Amt_Chng_Q4_Q1 <-
test$Total_Trans_Amt * test$Total_Amt_Chng_Q4_Q1
test_int$Total_Trans_Amt_Is_Female <-
test$Total_Trans_Amt * test$Is_Female
test_int$Total_Trans_Amt_Total_Relationship_Count <-
test$Total_Trans_Amt * test$Total_Relationship_Count
test_int$Dependant_count_Total_Ct_Chng_Q4_Q1 <-
test$Dependent_count * test$Total_Ct_Chng_Q4_Q1
test_int$Is_Female_Total_Ct_Chng_Q4_Q1 <-
test$Is_Female * test$Total_Ct_Chng_Q4_Q1
test_int$Customer_Age_Marital_Status <-
test$Customer_Age * test$Marital_Status
#Creation of train_bal with interactions
train_bal_int <- data.frame(train_bal)
train_bal_int$Total_Revolving_Bal_Avg_Utilization_Ratio <-
train_bal$Total_Revolving_Bal * train_bal$Avg_Utilization_Ratio
train_bal_int$Total_Trans_Amt_Total_Trans_Ct <-
train_bal$Total_Trans_Amt * train_bal$Total_Trans_Ct
train_bal_int$Total_Trans_Amt_Total_Amt_Chng_Q4_Q1 <-
train_bal$Total_Trans_Amt * train_bal$Total_Amt_Chng_Q4_Q1
train_bal_int$Total_Trans_Amt_Is_Female <-
train_bal$Total_Trans_Amt * train_bal$Is_Female
train_bal_int$Total_Trans_Amt_Total_Relationship_Count <-
train_bal$Total_Trans_Amt * train_bal$Total_Relationship_Count
train_bal_int$Dependant_count_Total_Ct_Chng_Q4_Q1 <-
train_bal$Dependent_count * train_bal$Total_Ct_Chng_Q4_Q1
train_bal_int$Is_Female_Total_Trans_Ct_Q4_Q1 <-
train_bal$Is_Female * train_bal$Total_Ct_Chng_Q4_Q1
train_bal_int$Customer_Age_Marital_Status <-
train_bal$Customer_Age * train_bal$Marital_Status
# Matrix without Attrition_Flag, Education_Level , Months_on_book and Avg_Open_To_Buy
train_mat <- data.matrix(train_int[,-c(1,5,8,14)])
test_mat <- data.matrix(test_int[,-c(1,5,8,14)])
ridge_u <- cv.glmnet(train_mat,train$Attrition_Flag, alpha = 0,
family = "binomial", type.measure = "class")
plot(ridge_u)
lambda_ridge_u <- ridge_u$lambda.min
lambda_ridge_u
#Threshold
Threshold <- 0.3
ridge_predict_u <- predict(ridge_u,test_mat,type = "response", s = lambda_ridge_u)
pred_ridge_u <- ifelse(ridge_predict_u >= Threshold , 1,0)
#Confusion matrix
c_mat_ridge_u <- table(test$Attrition_Flag,pred_ridge_u)
c_mat_ridge_u
#Accuracy
mean(pred_ridge_u==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_ridge_u <- c_mat_ridge_u[1,1]/sum(c_mat_ridge_u[1,])
Spec_ridge_u
#Precision / Positive Predicted Value
Prec_ridge_u <- c_mat_ridge_u[2,2]/sum(c_mat_ridge_u[,2])
Prec_ridge_u
#Recall / True Positive Rate / Sensitivity
Rec_ridge_u <- c_mat_ridge_u[2,2]/sum(c_mat_ridge_u[2,])
Rec_ridge_u
#F1 Score
F1_ridge_u <- 2 * (Prec_ridge_u * Rec_ridge_u)/(Prec_ridge_u + Rec_ridge_u)
F1_ridge_u
# Matrix without Attrition_Flag, Months_on_book,Credit_Limit and Avg_Open_To_Buy
train_mat_b <- data.matrix(train_bal_int[,-c(1,8,12,14)])
test_mat_b <- data.matrix(test_int[,-c(1,8,12,14)])
ridge_b <- cv.glmnet(train_mat_b,train_bal$Attrition_Flag, alpha = 0,
family = "binomial", type.measure = "class")
plot(ridge_b)
lambda_ridge_b <- ridge_b$lambda.min
lambda_ridge_b
#Threshold
Threshold <- 0.6
ridge_predict_b <- predict(ridge_b,test_mat_b,type = "response", s = lambda_ridge_b)
pred_ridge_b <- ifelse(ridge_predict_b >= Threshold , 1,0)
#Confusion matrix
c_mat_ridge_b <- table(test$Attrition_Flag,pred_ridge_b)
#Accuracy
mean(pred_ridge_b==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_ridge_b <- c_mat_ridge_b[1,1]/sum(c_mat_ridge_b[1,])
Spec_ridge_b
#Precision / Positive Predicted Value
Prec_ridge_b <- c_mat_ridge_b[2,2]/sum(c_mat_ridge_b[,2])
Prec_ridge_b
#Recall / True Positive Rate / Sensitivity
Rec_ridge_b <- c_mat_ridge_b[2,2]/sum(c_mat_ridge_b[2,])
Rec_ridge_b
#F1 Score
F1_ridge_b <- 2 * (Prec_ridge_b * Rec_ridge_b)/(Prec_ridge_b + Rec_ridge_b)
F1_ridge_b
#ROC curves
roc_ridge_u <- roc(test$Attrition_Flag ~ as.numeric(ridge_predict_u))
roc_ridge_b <- roc(test$Attrition_Flag ~ as.numeric(ridge_predict_b))
plot(roc_ridge_u, col = "black",print.auc = FALSE, auc.polygon = TRUE,
max.auc.polygon = TRUE, lwd=2)
plot(roc_ridge_b,add = TRUE,col = "blue", print.auc = FALSE, lwd=2)
text(0.3, 0.45, paste("AUC for ridge_u:", round(roc_ridge_u$auc, 3)), col = "black")
text(0.3, 0.38, paste("AUC for ridge_b:", round(roc_ridge_b$auc, 3)), col = "blue")
# Matrix without Attrition_Flag and Avg_Open_To_Buy
train_mat <- data.matrix(train_int[,-c(1)])
test_mat <- data.matrix(test_int[,-c(1)])
lasso_u <- cv.glmnet(train_mat,train$Attrition_Flag, alpha = 1,
family = "binomial", type.measure = "class")
plot(lasso_u)
lambda_lasso_u <- lasso_u$lambda.min
lambda_lasso_u
#Threshold
Threshold <- 0.4
lasso_predict_u <- predict(lasso_u,test_mat,type = "response", s = lambda_lasso_u)
pred_lasso_u <- ifelse(lasso_predict_u >= Threshold , 1,0)
#Confusion matrix
c_mat_lasso_u <- table(test$Attrition_Flag,pred_lasso_u)
c_mat_lasso_u
#Accuracy
mean(pred_lasso_u==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_lasso_u <- c_mat_lasso_u[1,1]/sum(c_mat_lasso_u[1,])
Spec_lasso_u
#Precision / Positive Predicted Value
Prec_lasso_u <- c_mat_lasso_u[2,2]/sum(c_mat_lasso_u[,2])
Prec_lasso_u
#Recall / True Positive Rate / Sensitivity
Rec_lasso_u <- c_mat_lasso_u[2,2]/sum(c_mat_lasso_u[2,])
Rec_lasso_u
#F1 Score
F1_lasso_u <- 2 * (Prec_lasso_u * Rec_lasso_u)/(Prec_lasso_u + Rec_lasso_u)
F1_lasso_u
# Matrix without Attrition_Flag
train_mat_b <- data.matrix(train_bal_int[,-c(1)])
test_mat_b <- data.matrix(test_int[,-c(1)])
lasso_b <- cv.glmnet(train_mat_b,train_bal$Attrition_Flag, alpha = 1,
family = "binomial", type.measure = "class")
plot(lasso_b)
lambda_lasso_b <- lasso_b$lambda.min
lambda_lasso_b
#Threshold
Threshold <- 0.8
lasso_predict_b <- predict(lasso_b,test_mat_b,type = "response", s = lambda_lasso_b)
pred_lasso_b <- ifelse(lasso_predict_b >= Threshold , 1,0)
#Confusion matrix
c_mat_lasso_b <- table(test$Attrition_Flag,pred_lasso_b)
c_mat_lasso_b
#Accuracy
mean(pred_lasso_b==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_lasso_b <- c_mat_lasso_b[1,1]/sum(c_mat_lasso_b[1,])
Spec_lasso_b
#Precision / Positive Predicted Value
Prec_lasso_b <- c_mat_lasso_b[2,2]/sum(c_mat_lasso_b[,2])
Prec_lasso_b
#Recall / True Positive Rate / Sensitivity
Rec_lasso_b <- c_mat_lasso_b[2,2]/sum(c_mat_lasso_b[2,])
Rec_lasso_b
#F1 Score
F1_lasso_b <- 2 * (Prec_lasso_b * Rec_lasso_b)/(Prec_lasso_b + Rec_lasso_b)
F1_lasso_b
#ROC curves
roc_lasso_u <- roc(test$Attrition_Flag ~ as.numeric(lasso_predict_u))
roc_lasso_b <- roc(test$Attrition_Flag ~ as.numeric(lasso_predict_b))
plot(roc_lasso_u, col = "black",print.auc = FALSE, auc.polygon = TRUE,
max.auc.polygon = TRUE, lwd=2)
plot(roc_lasso_b,add = TRUE,col = "blue", print.auc = FALSE, lwd=2)
text(0.3, 0.45, paste("AUC for lasso_u:", round(roc_lasso_u$auc, 3)), col = "black")
text(0.3, 0.38, paste("AUC for lasso_b:", round(roc_lasso_b$auc, 3)), col = "blue")
#Thresholds
Threshold1 <- 0.6
Threshold2 <- 0.7
Threshold3 <- 0.8
lasso_bal_predict_2 <- predict(lasso_b,test_mat_b,type = "response", s = lambda_lasso_b)
pred_1 <- ifelse(lasso_bal_predict_2 >= Threshold1 , 1,0)
pred_2 <- ifelse(lasso_bal_predict_2 >= Threshold2 , 1,0)
pred_3 <- ifelse(lasso_bal_predict_2 >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1 <- table(test$Attrition_Flag,pred_1)
c_mat_2 <- table(test$Attrition_Flag,pred_2)
c_mat_3 <- table(test$Attrition_Flag,pred_3)
c_mat_1
c_mat_2
c_mat_3
#Accuracy
mean(pred_1==test$Attrition_Flag)*100
mean(pred_2==test$Attrition_Flag)*100
mean(pred_3==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1 <- c_mat_1[1,1]/sum(c_mat_1[1,])
Spec_2 <- c_mat_2[1,1]/sum(c_mat_2[1,])
Spec_3 <- c_mat_3[1,1]/sum(c_mat_3[1,])
Spec_1
Spec_2
Spec_3
#Precision / Positive Predicted Value
Prec_1 <- c_mat_1[2,2]/sum(c_mat_1[,2])
Prec_2 <- c_mat_2[2,2]/sum(c_mat_2[,2])
Prec_3 <- c_mat_3[2,2]/sum(c_mat_3[,2])
Prec_1
Prec_2
Prec_3
#Recall / True Positive Rate / Sensitivity
Rec_1 <- c_mat_1[2,2]/sum(c_mat_1[2,])
Rec_2 <- c_mat_2[2,2]/sum(c_mat_2[2,])
Rec_3 <- c_mat_3[2,2]/sum(c_mat_3[2,])
Rec_1
Rec_2
Rec_3
#F1 Score
F1_1 <- 2 * (Prec_1 * Rec_1)/(Prec_1 + Rec_1)
F1_2 <- 2 * (Prec_2 * Rec_2)/(Prec_2 + Rec_2)
F1_3 <- 2 * (Prec_3 * Rec_3)/(Prec_3 + Rec_3)
F1_1
F1_2
F1_3
c_mat_lasso_u
#Threshold
Threshold <- 0.7
lasso_predict_b <- predict(lasso_b,test_mat_b,type = "response", s = lambda_lasso_b)
pred_lasso_b <- ifelse(lasso_predict_b >= Threshold , 1,0)
#Confusion matrix
c_mat_lasso_b <- table(test$Attrition_Flag,pred_lasso_b)
c_mat_lasso_b
#Threshold
Threshold <- 0.7
lasso_predict_b <- predict(lasso_b,test_mat_b,type = "response", s = lambda_lasso_b)
pred_lasso_b <- ifelse(lasso_predict_b >= Threshold , 1,0)
#Confusion matrix
c_mat_lasso_b <- table(test$Attrition_Flag,pred_lasso_b)
#Accuracy
mean(pred_lasso_b==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_lasso_b <- c_mat_lasso_b[1,1]/sum(c_mat_lasso_b[1,])
Spec_lasso_b
#Precision / Positive Predicted Value
Prec_lasso_b <- c_mat_lasso_b[2,2]/sum(c_mat_lasso_b[,2])
Prec_lasso_b
#Recall / True Positive Rate / Sensitivity
Rec_lasso_b <- c_mat_lasso_b[2,2]/sum(c_mat_lasso_b[2,])
Rec_lasso_b
#F1 Score
F1_lasso_b <- 2 * (Prec_lasso_b * Rec_lasso_b)/(Prec_lasso_b + Rec_lasso_b)
F1_lasso_b
#ROC curves
roc_lasso_u <- roc(test$Attrition_Flag ~ as.numeric(lasso_predict_u))
roc_lasso_b <- roc(test$Attrition_Flag ~ as.numeric(lasso_predict_b))
plot(roc_lasso_u, col = "black",print.auc = FALSE, auc.polygon = TRUE,
max.auc.polygon = TRUE, lwd=2)
plot(roc_lasso_b,add = TRUE,col = "blue", print.auc = FALSE, lwd=2)
text(0.3, 0.45, paste("AUC for lasso_u:", round(roc_lasso_u$auc, 3)), col = "black")
text(0.3, 0.38, paste("AUC for lasso_b:", round(roc_lasso_b$auc, 3)), col = "blue")
F1_i
F1_f
F1_lda_u
F1_qda_u
F1_ridge_u
F1_lasso_u
Rec_i
Rec_f
Rec_lda_u
Rec_qda_u
Rec_ridge_u
Rec_lasso_u
roc_i$auc
roc_f$auc
roc_lda_u$auc
roc_qda_u$auc
roc_ridge_u$auc
roc_lasso_u$auc
F1_i_bal
F1_f_bal
F1_lda_b
F1_qda_b
F1_ridge_b
F1_lasso_b
Rec_i_bal
Rec_f_bal
Rec_lda_b
Rec_qda_b
Rec_ridge_b
Rec_lasso_b
roc_i$auc
roc_f_bal$auc
roc_i_bal$auc
roc_lda_b$auc
roc_qda_b$auc
roc_ridge_b$auc
roc_lasso_b$auc
