F1_qda_u
F1_ridge_u
F1_lasso_u
Rec_i
Rec_f
Rec_lda_u
Rec_qda_u
Rec_ridge_u
Rec_lasso_u
roc_i$auc
roc_f$auc
roc_lda_u$auc
roc_qda_u$auc
roc_ridge_u$auc
roc_lasso_u$auc
F1_i_bal
F1_f_bal
F1_lda_b
F1_qda_b
F1_ridge_b
F1_lasso_b
Rec_i_bal
Rec_f_bal
Rec_lda_b
Rec_qda_b
Rec_ridge_b
Rec_lasso_b
roc_i$auc
roc_f_bal$auc
roc_i_bal$auc
roc_lda_b$auc
roc_qda_b$auc
roc_ridge_b$auc
roc_lasso_b$auc
#########
library("dplyr")
library("corrplot")
library("caTools")
library("ggpubr")
library("ROSE")
library("correlation")
library("moments") #to calculate skewness
library("olsrr") #to use ols_step_backward_p
library("MASS")
library("knitr")
library("forecast")
library("ggplot2")
library("PCAmixdata")
library("purrr")
library("corpcor")
library("car")
library("e1071")
library("ppcor")
library("pROC")
library("interactions")
library("glmnet")
library("formattable") # for giving a variable dictionary a better look
library("RColorBrewer")# for the visualization colorings
bank_data_origin <- read.csv('~/GitHub/Stats_23_Project/BankChurners.csv')
head(bank_data_origin)
summary(bank_data_origin)
dim(bank_data_origin)
bank_data <- subset(bank_data_origin, select = -c(Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1, Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2))
final_dim <- dim(bank_data)
final_dim
# BRIEF DESCRIPTION OF EACH VARIABLE
var.names <- c("Clientnum", "Attrition_Flag", "Customer_Age", "Gender", "Dependent_count",
"Education_Level", "Marital_Status", "Income_Category", "Card_Category", "Months_on_book",
"Total_Relationship_Count", "Months_Inactive_12_mon", "Contacts_Count_12_mon", "Credit_Limit",
"Total_Revolving_Bal", "Avg_Open_To_Buy", "Total_Amt_Chng_Q4_Q1", "Total_Trans_Amt",
"Total_Trans_Ct", "Total_Ct_Chng_Q4_Q1", "Avg_Utilization_Ratio")
descriptions <- c("refers to the distinct identification numbers assigned to customers, consisting of a unique sequence of 9 digits. The datasets contain a total of 10,127 customers with unique IDs.",
"refers to the current status of customers, indicating whether they are Existing Customers (current customers) or Attrited Customers (churned customers). There are two distinct values for this target/output variable.",
"represents the age of customers, with a range between 27 and 73.",
"is encoded as 'F' for Female and 'M' for Male.",
"represents the number of dependents associated with a customer.",
"represents the educational qualification of a customer. It encompasses seven distinct values: High School, Graduate, Uneducated, College, Post-graduate, Doctorate, and Unknown. The Unknown category includes 1519 customers.",
"represents the marital status of customers, with four unique values: Married, Single, Unknown, and Divorced. The Unknown category includes 749 customers.",
"represents the annual income category of cardholders: Less than 40K, 40K-60K, 60K-80K, 80K-120K, $120+, and Unknown. The Unknown category includes 1112 customers.",
"refers to a product variable that indicates the type of credit card held by customers. It includes four unique values: Blue, Gold, Silver, and Platinum.",
"represents the duration, in months, that an account holder has been a customer at the bank.",
"represents the number of products held by a customer.",
"represents the number of months during which a customer has been inactive in the last 12 months (1 year).",
"represents the number of times a customer has contacted the bank.",
"represents the credit limit on the customer's credit card.",
"represents the total revolving balance on the customer's credit card.",
"represents the average Open to Buy Credit Line for the last 12 months.",
"represents the change in transaction amount from the fourth quarter (Q4) to the first quarter (Q1).",
"represents the total transaction amount in the last 12 months.",
"represents the total transaction count in the last 12 months.",
"represents the change in transaction count from the fourth quarter (Q4) to the first quarter (Q1).",
"represents the average card utilization ratio.")
var.dict <- as.data.frame(descriptions, row.names = var.names, )
formattable(var.dict)
# DATA PREPERATION
#display of the categorical variables
table(bank_data$CLIENTNUM)
table(bank_data$Attrition_Flag)
table(bank_data$Gender)
table(bank_data$Education_Level)
table(bank_data$Marital_Status)
table(bank_data$Income_Category)
table(bank_data$Card_Category)
#Change Unknown value to NA
bank_data_NA <- data.frame(bank_data)
bank_data_NA[bank_data_NA=='Unknown'] <- NA
#Build a dataset without missing values
bank_data_withoutNA <- na.omit(bank_data_NA)
#We convert categorical variables into numerical
bank_data_withoutNA_quan <- data.frame(bank_data_withoutNA)
#change 'Existing Customer' to 1 and 'Attrited Customer' to 0 and add new column to quantitative
bank_data_withoutNA_quan$Attrition_Flag <- as.numeric(bank_data_withoutNA_quan$Attrition_Flag == "Attrited Customer")
bank_data_withoutNA_quan$Gender <- as.numeric(bank_data_withoutNA_quan$Gender == "F")
bank_data_withoutNA_quan <- bank_data_withoutNA_quan %>% rename("Is_Female" = "Gender")
order_education_level <- list("Uneducated" = 1,
"High School" = 2,
"College" = 3,
"Graduate" = 4,
"Post-Graduate" = 5,
"Doctorate" = 6)
bank_data_withoutNA_quan$Education_Level <- unlist(order_education_level[as.character(bank_data_withoutNA_quan$Education_Level)])
order_Marital_Status <- list("Single" = 1,
"Married" = 2,
"Divorced" = 3)
bank_data_withoutNA_quan$Marital_Status <- unlist(order_Marital_Status[as.character(bank_data_withoutNA_quan$Marital_Status)])
order_Income_Category <- list("Less than $40K" = 1,
"$40K - $60K" = 2,
"$60K - $80K" = 3,
"$80K - $120K" = 4,
"$120K +" = 5)
bank_data_withoutNA_quan$Income_Category <- unlist(order_Income_Category[as.character(bank_data_withoutNA_quan$Income_Category)])
order_Card_Category <- list("Blue" = 1,
"Silver" = 2,
"Gold" = 3,
"Platinum" = 4)
bank_data_withoutNA_quan$Card_Category <- unlist(order_Card_Category[as.character(bank_data_withoutNA_quan$Card_Category)])
#Categorical Value Visualizations
#Bar plots
par(mfrow=c(2,2))
myPalette <- brewer.pal(6, "Set2")
ggplot(bank_data_withoutNA_quan, aes(x = as.factor(Income_Category), fill = factor(Attrition_Flag))) + geom_bar() + labs(fill = "Attrition Flag")
ggplot(bank_data_withoutNA_quan, aes(x = as.factor(Marital_Status), fill = factor(Attrition_Flag))) + geom_bar() + labs(fill = "Attrition Flag")
ggplot(bank_data_withoutNA_quan, aes(x = as.factor(Education_Level), fill = factor(Attrition_Flag))) + geom_bar() + labs(fill = "Attrition Flag")
ggplot(bank_data_withoutNA_quan, aes(x = as.factor(Card_Category), fill = factor(Attrition_Flag))) + geom_bar() + labs(fill = "Attrition Flag")
# Card Category
ggplot(bank_data_withoutNA_quan, aes(x=Months_on_book, y= Credit_Limit, shape = as.factor(Card_Category), color= as.factor(Card_Category)))+
geom_point() + geom_smooth(method=lm, se=FALSE, fullrange=TRUE)
#Numerical columns analysis
attach(bank_data_withoutNA_quan)
cust.age.boxplot <- boxplot(Customer_Age, main="Customer age", ylab = "age")
months.onbook.boxplot <- boxplot(Months_on_book, main="Months on Book", ylab = "months")
reltn.cnt.boxplot <- boxplot(Total_Relationship_Count, main="Total_Relationship_Count", ylab = "#")
mnths.inact.boxplot <- boxplot(Months_Inactive_12_mon,  main="Months_Inactive_12_mon", ylab = "months")
cntc.cnt.boxplot <- boxplot(Contacts_Count_12_mon, main="Contacts_Count_12_mon", ylab = "#")
credit.limit.boxplot <- boxplot(Credit_Limit,  main="Credit_Limit", ylab = "Dollars")
ttl.revbal.boxplot <- boxplot(Total_Revolving_Bal, main="Total_Revolving_Bal", ylab = "Dollars")
avg.opnbuy.boxplot <- boxplot(Avg_Open_To_Buy, main="Avg_Open_To_Buy", ylab = "Dollars")
total.amtchg.boxplot <- boxplot(Total_Amt_Chng_Q4_Q1, main="Total_Amt_Chng_Q4_Q1", ylab = "Dollars")
ttl.transct.boxplot <- boxplot(Total_Trans_Ct, main="Total_Trans_Ct", ylab = "#")
total.cntchg.boxplot <- boxplot(Total_Ct_Chng_Q4_Q1, main="Total_Ct_Chng_Q4_Q1", ylab = "Dollars")
avg.utilrate.boxplot <- boxplot(Avg_Utilization_Ratio, main="Avg_Utilization_Ratio", ylab = "Ratio")
#Since the outliers in most of the numerical columns can be identifying on whether the customer is going to churn we decided to keep them in the data set
#Extracting Outliers from age and Rescoping the study to only focus on Blue Cards
#using the 1st quartile-1.5*IQR and 3rd quartile+1.5*IQR rule,
#it is seen that customers over the age of 70 are outliers
age.exc.list <- boxplot.stats(bank_data_withoutNA_quan$Customer_Age)$out
#Since most of the data is coming from the Blue cards and there is a visible difference on many parameters among categories, we decided to only focus on blue card category
card.exc.list <- c(2, 3, 4)
cleaned_bank_data_withoutNA_quan <- subset(bank_data_withoutNA_quan,!((Customer_Age %in% age.exc.list)| (Card_Category %in% card.exc.list)))
cleaned_bank_data_withoutNA_quan<- subset(cleaned_bank_data_withoutNA_quan, select = -c(Card_Category))
cleaned_bank_data_withoutNA_quan
# Descriptive Graphs
#histogram
Cust.age.hist <- hist(cleaned_bank_data_withoutNA_quan$Customer_Age, xlab="age", ylab="freq",
main="Customer age distribution", col="orange")
Cust.age.hist
#using the histogram, dividing ages into 4 groups seems satisfying
#Creating age groups
cleaned_bank_data_withoutNA_quan[cleaned_bank_data_withoutNA_quan$Customer_Age <= 34, "age_group"] <- 1
cleaned_bank_data_withoutNA_quan[cleaned_bank_data_withoutNA_quan$Customer_Age > 34 & cleaned_bank_data_withoutNA_quan$Customer_Age <= 44, "age_group"] <- 2
cleaned_bank_data_withoutNA_quan[cleaned_bank_data_withoutNA_quan$Customer_Age > 44 & cleaned_bank_data_withoutNA_quan$Customer_Age <= 54, "age_group"] <- 3
cleaned_bank_data_withoutNA_quan[cleaned_bank_data_withoutNA_quan$Customer_Age > 54, "age_group"] <- 4
#grouped age bar plot
par(mfrow=c(1,1))
cleaned_bank_data_withoutNA_quan %>%
group_by(age_group) %>% summarise(N=n()) %>%
ggplot(aes(x=age_group,y=N,fill=age_group))+
geom_bar(stat = 'identity',color='black')+
scale_y_continuous(labels = scales::comma_format(accuracy = 2))+
geom_text(aes(label=N),vjust=-0.25,fontface='bold')+
theme_bw()+
theme(axis.text = element_text(color='black',face='bold'),
axis.title = element_text(color='black',face='bold'),
legend.text = element_text(color='black',face='bold'),
legend.title = element_text(color='black',face='bold'))
# grouped age piechart
age.labels <- c("<=34", "35-44", "45-54", ">=55")
cust.age.piechart <- pie(count(cleaned_bank_data_withoutNA_quan, age_group)$n, border="white", col=myPalette, labels = age.labels)
#Dependent Count
depcount.labels <- c(0, 1, 2, 3, 4, 5)
dependent.count.piechart <- pie(count(cleaned_bank_data_withoutNA_quan, Dependent_count)$n, border="white", col=myPalette, labels = depcount.labels)
#Months inactive
library(yarrr) #to make colors transparent
barplot(table(factor(Months_Inactive_12_mon,levels=min(Months_Inactive_12_mon):max(Months_Inactive_12_mon))), col = yarrr::transparent('red',trans.val = 0.9))
barplot(table(factor(Contacts_Count_12_mon,levels=min(Contacts_Count_12_mon):max(Contacts_Count_12_mon))), col = yarrr::transparent('blue', trans.val = 0.8), add = TRUE)
hist(cleaned_bank_data_withoutNA_quan$Total_Trans_Ct)
int.hist = function(x,ylab="Frequency",...) {
barplot(table(factor(x,levels=min(x):max(x))),space=0,xaxt="n",ylab=ylab,...);axis(1)
}
dev.off(dev.list()["RStudioGD"]) #to clear the previous plots on the screen
fig.dim = c(4, 3)
#Histograms
attach(cleaned_bank_data_withoutNA_quan)
par(mfrow=c(3,2))
hist(Avg_Open_To_Buy)
hist(Total_Trans_Amt)
hist(Avg_Utilization_Ratio)
hist(Months_on_book)
hist(Credit_Limit)
hist(Months_Inactive_12_mon)
#Correlation matrix
cor_mat_new <- cor(bank_data_withoutNA_quan[2:15])
corrplot(cor_mat_new,method = "number",type = "upper", tl.pos = "td",tl.cex=0.5, tl.col = "black" ,diag = FALSE)
set.seed(0237)
sample <- sample.split(cleaned_bank_data_withoutNA_quan[,2:20]$Attrition_Flag,
SplitRatio = 0.75)
train <- subset(cleaned_bank_data_withoutNA_quan[,2:20],sample == TRUE)
test <- subset(cleaned_bank_data_withoutNA_quan[,2:20],sample == FALSE)
#Proportion of Attrited and Existing Customer in Training set
prop.table(table(train$Attrition_Flag))
#Proportion of Attrited and Existing Customer in Test set
prop.table(table(test$Attrition_Flag))
#Mixed Sampling with 50% of Attrited Customer
train_bal <- ovun.sample(Attrition_Flag~.,data = train, method = "both", p = 0.5, N =4948)$data
attach(train)
train$Attrition_Flag <- as.numeric(train$Attrition_Flag)
#Correlation matrix
cor_mat <- cor(train)
corrplot(cor_mat,method = "number",type = "upper",number.cex = 0.6, tl.pos = "td",tl.cex=0.5, tl.col = "black" ,diag = FALSE)
#Correlation with Attrition_Flag
corrplot(cor_mat[1,,drop=FALSE],method = "number",number.cex = 0.6, cl.pos = "n",tl.col = "black" ,tl.cex=0.5,diag = FALSE)
#Partial correlations (Takes time)
correlation(train[,-14],partial = TRUE)
#Partial Correlation matrix
part_cor_mat <- pcor(train[,-14])$estimate
corrplot(part_cor_mat, method = "number",type = "upper",number.cex = 0.6, tl.pos = "td",tl.cex=0.5, tl.col = "black" ,diag = FALSE)
Customer <- as.factor(train$Attrition_Flag)
a <- ggplot(train, aes(x = Total_Trans_Ct, fill = Customer)) +
geom_density(alpha=0.3) + ggtitle("Total_Trans_Ct") +
scale_fill_manual(values = c("darkgrey","red"),labels = c("Existing","Attrited"))
b <- ggplot(train, aes(x = Total_Relationship_Count, fill = Customer)) +
geom_bar(aes(y = after_stat(prop) ),alpha=0.3, position = "dodge") +
ggtitle("Total_Relationship_Count") +
scale_fill_manual(values = c("darkgrey","red"),labels = c("Existing","Attrited"))
c <- ggplot(train, aes(x = Total_Trans_Amt, fill = Customer)) +
geom_density(alpha=0.3) + ggtitle("Total_Trans_Amt") +
scale_fill_manual(values = c("darkgrey","red"),labels = c("Existing","Attrited"))
d <- ggplot(train, aes(x = Total_Ct_Chng_Q4_Q1, fill = Customer)) +
geom_density(alpha=0.3) + ggtitle("Total_Ct_Chng_Q4_Q1")+
scale_fill_manual(values = c("darkgrey","red"),labels = c("Existing","Attrited"))
e <- ggplot(train, aes(x = Contacts_Count_12_mon, fill = Customer)) +
geom_bar(aes(y = after_stat(prop) ),alpha=0.3, position = "dodge") +
ggtitle("Contacts_Count_12_mon") +
scale_fill_manual(values = c("darkgrey","red"),labels = c("Existing","Attrited"))
f <- ggplot(train, aes(x = Total_Revolving_Bal, fill = Customer)) +
geom_density(alpha=0.3) + ggtitle("Total_Revolving_Bal") +
scale_fill_manual(values = c("darkgrey","red"),labels = c("Existing","Attrited"))
g <- ggplot(train, aes(x = Months_Inactive_12_mon, fill = Customer)) +
geom_bar(aes(y = after_stat(prop) ),alpha=0.3, position = "dodge") +
ggtitle("Months_Inactive_12_mon") +
scale_fill_manual(values = c("darkgrey","red"),labels = c("Existing","Attrited"))
h <- ggplot(train, aes(x = Is_Female, fill = Customer)) +
geom_bar(aes(y = after_stat(prop) ),alpha=0.3, position = "dodge") +
ggtitle("Is_Female") +
scale_fill_manual(values = c("darkgrey","red"),labels = c("Existing","Attrited"))
ggarrange(a,b,c,d,e,f,g,h,nrow=4,ncol=2)
# Unbalanced model
glm_1 <- glm(data = train,Attrition_Flag~ . - Avg_Open_To_Buy ,family = "binomial")
summary(glm_1)
#Thresholds
Threshold1 <- 0.3
Threshold2 <- 0.4
Threshold3 <- 0.5
pred_glm_i <- predict(glm_1,test,type="response")
pred_1_i <- ifelse(pred_glm_i >= Threshold1 , 1,0)
pred_2_i <- ifelse(pred_glm_i >= Threshold2 , 1,0)
pred_3_i <- ifelse(pred_glm_i >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1_i <- table(test$Attrition_Flag,pred_1_i)
c_mat_2_i <- table(test$Attrition_Flag,pred_2_i)
c_mat_3_i <- table(test$Attrition_Flag,pred_3_i)
c_mat_1_i
c_mat_2_i
c_mat_3_i
#Accuracy
mean(pred_1_i==test$Attrition_Flag)*100
mean(pred_2_i==test$Attrition_Flag)*100
mean(pred_3_i==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1_i <- c_mat_1_i[1,1]/sum(c_mat_1_i[1,])
Spec_2_i <- c_mat_2_i[1,1]/sum(c_mat_2_i[1,])
Spec_3_i <- c_mat_3_i[1,1]/sum(c_mat_3_i[1,])
Spec_1_i
Spec_2_i
Spec_3_i
#Precision / Positive Predicted Value
Prec_1_i <- c_mat_1_i[2,2]/sum(c_mat_1_i[,2])
Prec_2_i <- c_mat_2_i[2,2]/sum(c_mat_2_i[,2])
Prec_3_i <- c_mat_3_i[2,2]/sum(c_mat_3_i[,2])
Prec_1_i
Prec_2_i
Prec_3_i
#Recall / True Positive Rate / Sensitivity
Rec_1_i <- c_mat_1_i[2,2]/sum(c_mat_1_i[2,])
Rec_2_i <- c_mat_2_i[2,2]/sum(c_mat_2_i[2,])
Rec_3_i <- c_mat_3_i[2,2]/sum(c_mat_3_i[2,])
Rec_1_i
Rec_2_i
Rec_3_i
#F1 Score
F1_1_i <- 2 * (Prec_1_i * Rec_1_i)/(Prec_1_i + Rec_1_i)
F1_2_i <- 2 * (Prec_2_i * Rec_2_i)/(Prec_2_i + Rec_2_i)
F1_3_i <- 2 * (Prec_3_i * Rec_3_i)/(Prec_3_i + Rec_3_i)
F1_1_i
F1_2_i
F1_3_i
#VIF
vif(glm_1)
#Update Checking p-values and AIC
glm_2 <- update(glm_1, . ~ . - Avg_Utilization_Ratio - Months_on_book)
summary(glm_2)
vif(glm_2)
glm_3 <- update(glm_2, . ~ . - Months_on_book)
summary(glm_3)
glm_4 <- update(glm_3, . ~ . + Total_Amt_Chng_Q4_Q1*Customer_Age + Total_Amt_Chng_Q4_Q1*Dependent_count
+ Total_Amt_Chng_Q4_Q1*Total_Trans_Amt + Total_Amt_Chng_Q4_Q1*Total_Trans_Ct)
summary(glm_4)
#Show that there is interaction
interact_plot(glm_4,pred = Total_Amt_Chng_Q4_Q1,modx = Customer_Age, outcome.scale = "link")
interact_plot(glm_4,pred = Total_Amt_Chng_Q4_Q1,modx = Dependent_count, outcome.scale = "link")
interact_plot(glm_4,pred = Total_Amt_Chng_Q4_Q1,modx = Total_Trans_Amt, outcome.scale = "link")
interact_plot(glm_4,pred = Total_Amt_Chng_Q4_Q1,modx = Total_Trans_Ct, outcome.scale = "link")
glm_5 <- update(glm_4, . ~ . + Total_Revolving_Bal*Credit_Limit + Total_Revolving_Bal*Avg_Utilization_Ratio)
summary(glm_5)
#Interaction
interact_plot(glm_5,pred = Total_Revolving_Bal,modx = Credit_Limit, outcome.scale = "link")
interact_plot(glm_5,pred = Total_Revolving_Bal,modx = Avg_Utilization_Ratio, outcome.scale = "link")
glm_6 <- update(glm_5, . ~ . + Credit_Limit*Avg_Utilization_Ratio)
summary(glm_6)
#Show that there is interaction
interact_plot(glm_6,pred = Credit_Limit,modx = Avg_Utilization_Ratio, outcome.scale = "link")
glm_7 <- update(glm_6, . ~ . + Total_Ct_Chng_Q4_Q1*Is_Female)
summary(glm_7)
#Interaction
interact_plot(glm_7,pred = Total_Ct_Chng_Q4_Q1,modx = Is_Female, outcome.scale = "link")
glm_8 <- update(glm_7, . ~ . - Education_Level)
summary(glm_8)
glm_9 <- update(glm_8, . ~ .+ Customer_Age*Marital_Status)
summary(glm_9)
#Interaction
interact_plot(glm_9,pred = Customer_Age,modx = Marital_Status , outcome.scale = "link")
pred_glm_f <- predict(glm_9,test,type="response")
pred_1_f <- ifelse(pred_glm_f >= Threshold1 , 1,0)
pred_2_f <- ifelse(pred_glm_f >= Threshold2 , 1,0)
pred_3_f <- ifelse(pred_glm_f >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1_f <- table(test$Attrition_Flag,pred_1_f)
c_mat_2_f <- table(test$Attrition_Flag,pred_2_f)
c_mat_3_f <- table(test$Attrition_Flag,pred_3_f)
c_mat_1_f
c_mat_2_f
c_mat_3_f
#Accuracy
mean(pred_1_f==test$Attrition_Flag)*100
mean(pred_2_f==test$Attrition_Flag)*100
mean(pred_3_f==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1_f <- c_mat_1_f[1,1]/sum(c_mat_1_f[1,])
Spec_2_f <- c_mat_2_f[1,1]/sum(c_mat_2_f[1,])
Spec_3_f <- c_mat_3_f[1,1]/sum(c_mat_3_f[1,])
Spec_1_f
Spec_2_f
Spec_3_f
#Precision / Positive Predicted Value
Prec_1_f <- c_mat_1_f[2,2]/sum(c_mat_1_f[,2])
Prec_2_f <- c_mat_2_f[2,2]/sum(c_mat_2_f[,2])
Prec_3_f <- c_mat_3_f[2,2]/sum(c_mat_3_f[,2])
Prec_1_f
Prec_2_f
Prec_3_f
#Recall / True Positive Rate / Sensitivity
Rec_1_f <- c_mat_1_f[2,2]/sum(c_mat_1_f[2,])
Rec_2_f <- c_mat_2_f[2,2]/sum(c_mat_2_f[2,])
Rec_3_f <- c_mat_3_f[2,2]/sum(c_mat_3_f[2,])
Rec_1_f
Rec_2_f
Rec_3_f
#F1 Score
F1_1_f <- 2 * (Prec_1_f * Rec_1_f)/(Prec_1_f + Rec_1_f)
F1_2_f <- 2 * (Prec_2_f * Rec_2_f)/(Prec_2_f + Rec_2_f)
F1_3_f <- 2 * (Prec_3_f * Rec_3_f)/(Prec_3_f + Rec_3_f)
F1_1_f
F1_2_f
F1_3_f
#ROC curves
roc_i <- roc(test$Attrition_Flag ~ pred_glm_i)
roc_f <- roc(test$Attrition_Flag ~ pred_glm_f)
AUC_i <- auc(roc_i)
AUC_f <- auc(roc_f)
plot(roc_i, col = "black",print.auc = TRUE, auc.polygon = TRUE, max.auc.polygon = TRUE, lwd=2,print.auc.x = 0.5,print.auc.y = 0.5)
plot(roc_f,add = TRUE,col = "blue", print.auc = TRUE, lwd=2, print.auc.x = 0.5,print.auc.y = 0.43)
#Best thresholds and Best Sensitivity and Specificity
Best_Treshold_i <- coords(roc_i,"best",best.method = "closest.topleft")$threshold
Best_pred_i <- ifelse(pred_glm_i >= Best_Treshold_i , 1,0)
Best_c_mat_i <- table(test$Attrition_Flag,Best_pred_i)
Best_Spec_i <- Best_c_mat_i[1,1]/sum(Best_c_mat_i[1,])
Best_Sens_i <- Best_c_mat_i[2,2]/sum(Best_c_mat_i[2,])
Best_Treshold_f <- coords(roc_f,"best",best.method = "closest.topleft")$threshold
Best_pred_f <- ifelse(pred_glm_f >= Best_Treshold_f , 1,0)
Best_c_mat_f <- table(test$Attrition_Flag,Best_pred_f)
Best_Spec_f <- Best_c_mat_f[1,1]/sum(Best_c_mat_f[1,])
Best_Sens_f <- Best_c_mat_f[2,2]/sum(Best_c_mat_f[2,])
#Table to show them
Table_mat <-  matrix(c(Best_Treshold_i,Best_Spec_i,Best_Sens_i,Best_Treshold_f,Best_Spec_f,Best_Sens_f), ncol=3, byrow=TRUE)
colnames(Table_mat) <- c("Threshold","Specificity","Sensitivity")
rownames(Table_mat) <- c("Initial model","Final model")
Tab <- as.table(Table_mat)
show(Tab)
#Model with balanced train set
glm_1_bal <- glm(data = train_bal,Attrition_Flag~ . - Avg_Open_To_Buy,family = "binomial")
summary(glm_1_bal)
#Thresholds
Threshold1 <- 0.6
Threshold2 <- 0.7
Threshold3 <- 0.8
pred_glm_bal_i <- predict(glm_1_bal,test,type="response")
pred_1_i <- ifelse(pred_glm_bal_i >= Threshold1 , 1,0)
pred_2_i <- ifelse(pred_glm_bal_i >= Threshold2 , 1,0)
pred_3_i <- ifelse(pred_glm_bal_i >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1_i <- table(test$Attrition_Flag,pred_1_i)
c_mat_2_i <- table(test$Attrition_Flag,pred_2_i)
c_mat_3_i <- table(test$Attrition_Flag,pred_3_i)
c_mat_1_i
c_mat_2_i
c_mat_3_i
#Accuracy
mean(pred_1_i==test$Attrition_Flag)*100
mean(pred_2_i==test$Attrition_Flag)*100
mean(pred_3_i==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1_i <- c_mat_1_i[1,1]/sum(c_mat_1_i[1,])
Spec_2_i <- c_mat_2_i[1,1]/sum(c_mat_2_i[1,])
Spec_3_i <- c_mat_3_i[1,1]/sum(c_mat_3_i[1,])
Spec_1_i
Spec_2_i
Spec_3_i
#Precision / Positive Predicted Value
Prec_1_i <- c_mat_1_i[2,2]/sum(c_mat_1_i[,2])
Prec_2_i <- c_mat_2_i[2,2]/sum(c_mat_2_i[,2])
Prec_3_i <- c_mat_3_i[2,2]/sum(c_mat_3_i[,2])
Prec_1_i
Prec_2_i
Prec_3_i
#Recall / True Positive Rate / Sensitivity
Rec_1_i <- c_mat_1_i[2,2]/sum(c_mat_1_i[2,])
Rec_2_i <- c_mat_2_i[2,2]/sum(c_mat_2_i[2,])
Rec_3_i <- c_mat_3_i[2,2]/sum(c_mat_3_i[2,])
Rec_1_i
Rec_2_i
Rec_3_i
#F1 Score
F1_1_i <- 2 * (Prec_1_i * Rec_1_i)/(Prec_1_i + Rec_1_i)
F1_2_i <- 2 * (Prec_2_i * Rec_2_i)/(Prec_2_i + Rec_2_i)
F1_3_i <- 2 * (Prec_3_i * Rec_3_i)/(Prec_3_i + Rec_3_i)
F1_1_i
F1_2_i
F1_3_i
#VIF
vif(glm_1)
#Update Checking p-values and AIC
glm_2_bal <- update(glm_1_bal, . ~ . - Months_on_book)
summary(glm_2_bal)
vif(glm_2_bal)
glm_3_bal <- update(glm_2_bal, . ~ . - Months_on_book)
summary(glm_3_bal)
glm_4_bal <- update(glm_3_bal, . ~ . + Total_Amt_Chng_Q4_Q1*Customer_Age + Total_Amt_Chng_Q4_Q1*Dependent_count
+ Total_Amt_Chng_Q4_Q1*Total_Trans_Amt)
summary(glm_4_bal)
#Show that there is interaction
interact_plot(glm_4_bal,pred = Total_Amt_Chng_Q4_Q1,modx = Customer_Age, outcome.scale = "link")
interact_plot(glm_4_bal,pred = Total_Amt_Chng_Q4_Q1,modx = Dependent_count, outcome.scale = "link")
interact_plot(glm_4_bal,pred = Total_Amt_Chng_Q4_Q1,modx = Total_Trans_Amt, outcome.scale = "link")
glm_5_bal <- update(glm_4_bal, . ~ . + Total_Revolving_Bal*Credit_Limit + Total_Revolving_Bal*Avg_Utilization_Ratio)
summary(glm_5_bal)
#Interaction
interact_plot(glm_5_bal,pred = Total_Revolving_Bal,modx = Credit_Limit, outcome.scale = "link")
interact_plot(glm_5_bal,pred = Avg_Utilization_Ratio,modx = Total_Revolving_Bal, outcome.scale = "link")
glm_6_bal <- update(glm_5_bal, . ~ . + Credit_Limit*Avg_Utilization_Ratio)
summary(glm_6_bal)
#Show that there is interaction
interact_plot(glm_6_bal,pred = Avg_Utilization_Ratio,modx = Credit_Limit, outcome.scale = "link")
glm_7_bal <- update(glm_6_bal, . ~ . + Total_Ct_Chng_Q4_Q1*Is_Female)
summary(glm_7_bal)
glm_7_bal <- update(glm_6_bal, . ~ . + Total_Ct_Chng_Q4_Q1*Is_Female)
summary(glm_7_bal)
#Interaction
interact_plot(glm_7_bal,pred = Total_Ct_Chng_Q4_Q1,modx = Is_Female, outcome.scale = "link")
glm_8_bal <- update(glm_7_bal, . ~ . + Customer_Age*Marital_Status)
summary(glm_8_bal)
#Interaction
interact_plot(glm_8_bal,pred = Customer_Age,modx = Marital_Status, outcome.scale = "link")
