#Creation of train and test set with interactions
train_int <- data.frame(train)
train_int$Total_Revolving_Bal_Avg_Utilization_Ratio <-
train$Total_Revolving_Bal * train$Avg_Utilization_Ratio
train_int$Total_Trans_Amt_Total_Trans_Ct <-
train$Total_Trans_Amt * train$Total_Trans_Ct
train_int$Total_Trans_Amt_Total_Amt_Chng_Q4_Q1 <-
train$Total_Trans_Amt * train$Total_Amt_Chng_Q4_Q1
train_int$Total_Trans_Amt_Is_Female <-
train$Total_Trans_Amt * train$Is_Female
train_int$Total_Trans_Amt_Total_Relationship_Count <-
train$Total_Trans_Amt * train$Total_Relationship_Count
train_int$Dependant_count_Total_Ct_Chng_Q4_Q1 <-
train$Dependent_count * train$Total_Ct_Chng_Q4_Q1
train_int$Is_Female_Total_Ct_Chng_Q4_Q1 <-
train$Is_Female * train$Total_Ct_Chng_Q4_Q1
train_int$Customer_Age_Marital_Status <-
train$Customer_Age * train$Marital_Status
test_int <- data.frame(test)
test_int$Total_Revolving_Bal_Avg_Utilization_Ratio <-
test$Total_Revolving_Bal * test$Avg_Utilization_Ratio
test_int$Total_Trans_Amt_Total_Trans_Ct <-
test$Total_Trans_Amt * test$Total_Trans_Ct
test_int$Total_Trans_Amt_Total_Amt_Chng_Q4_Q1 <-
test$Total_Trans_Amt * test$Total_Amt_Chng_Q4_Q1
test_int$Total_Trans_Amt_Is_Female <-
test$Total_Trans_Amt * test$Is_Female
test_int$Total_Trans_Amt_Total_Relationship_Count <-
test$Total_Trans_Amt * test$Total_Relationship_Count
test_int$Dependant_count_Total_Ct_Chng_Q4_Q1 <-
test$Dependent_count * test$Total_Ct_Chng_Q4_Q1
test_int$Is_Female_Total_Ct_Chng_Q4_Q1 <-
test$Is_Female * test$Total_Ct_Chng_Q4_Q1
test_int$Customer_Age_Marital_Status <-
test$Customer_Age * test$Marital_Status
#Creation of train_bal with interactions
train_bal_int <- data.frame(train_bal)
train_bal_int$Total_Revolving_Bal_Avg_Utilization_Ratio <-
train_bal$Total_Revolving_Bal * train_bal$Avg_Utilization_Ratio
train_bal_int$Total_Trans_Amt_Total_Trans_Ct <-
train_bal$Total_Trans_Amt * train_bal$Total_Trans_Ct
train_bal_int$Total_Trans_Amt_Total_Amt_Chng_Q4_Q1 <-
train_bal$Total_Trans_Amt * train_bal$Total_Amt_Chng_Q4_Q1
train_bal_int$Total_Trans_Amt_Is_Female <-
train_bal$Total_Trans_Amt * train_bal$Is_Female
train_bal_int$Total_Trans_Amt_Total_Relationship_Count <-
train_bal$Total_Trans_Amt * train_bal$Total_Relationship_Count
train_bal_int$Dependant_count_Total_Ct_Chng_Q4_Q1 <-
train_bal$Dependent_count * train_bal$Total_Ct_Chng_Q4_Q1
train_bal_int$Is_Female_Total_Trans_Ct_Q4_Q1 <-
train_bal$Is_Female * train_bal$Total_Ct_Chng_Q4_Q1
train_bal_int$Customer_Age_Marital_Status <-
train_bal$Customer_Age * train_bal$Marital_Status
# Matrix without Attrition_Flag, Education_Level , Months_on_book and Avg_Open_To_Buy
train_mat <- data.matrix(train_int[,-c(1,5,8,14)])
test_mat <- data.matrix(test_int[,-c(1,5,8,14)])
ridge_u <- cv.glmnet(train_mat,train$Attrition_Flag, alpha = 0,
family = "binomial", type.measure = "class")
plot(ridge_u)
lambda_ridge_u <- ridge_u$lambda.min
lambda_ridge_u
#Threshold
Threshold <- 0.3
ridge_predict_u <- predict(ridge_u,test_mat,type = "response", s = lambda_ridge_u)
pred_ridge_u <- ifelse(ridge_predict_u >= Threshold , 1,0)
#Confusion matrix
c_mat_ridge_u <- table(test$Attrition_Flag,pred_ridge_u)
c_mat_ridge_u
#Accuracy
mean(pred_ridge_u==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_ridge_u <- c_mat_ridge_u[1,1]/sum(c_mat_ridge_u[1,])
Spec_ridge_u
#Precision / Positive Predicted Value
Prec_ridge_u <- c_mat_ridge_u[2,2]/sum(c_mat_ridge_u[,2])
Prec_ridge_u
#Recall / True Positive Rate / Sensitivity
Rec_ridge_u <- c_mat_ridge_u[2,2]/sum(c_mat_ridge_u[2,])
Rec_ridge_u
#F1 Score
F1_ridge_u <- 2 * (Prec_ridge_u * Rec_ridge_u)/(Prec_ridge_u + Rec_ridge_u)
F1_ridge_u
# Matrix without Attrition_Flag, Months_on_book,Credit_Limit and Avg_Open_To_Buy
train_mat_b <- data.matrix(train_bal_int[,-c(1,8,12,14)])
test_mat_b <- data.matrix(test_int[,-c(1,8,12,14)])
ridge_b <- cv.glmnet(train_mat_b,train_bal$Attrition_Flag, alpha = 0,
family = "binomial", type.measure = "class")
plot(ridge_b)
lambda_ridge_b <- ridge_b$lambda.min
lambda_ridge_b
#Threshold
Threshold <- 0.6
ridge_predict_b <- predict(ridge_b,test_mat_b,type = "response", s = lambda_ridge_b)
pred_ridge_b <- ifelse(ridge_predict_b >= Threshold , 1,0)
#Confusion matrix
c_mat_ridge_b <- table(test$Attrition_Flag,pred_ridge_b)
#Accuracy
mean(pred_ridge_b==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_ridge_b <- c_mat_ridge_b[1,1]/sum(c_mat_ridge_b[1,])
Spec_ridge_b
#Precision / Positive Predicted Value
Prec_ridge_b <- c_mat_ridge_b[2,2]/sum(c_mat_ridge_b[,2])
Prec_ridge_b
#Recall / True Positive Rate / Sensitivity
Rec_ridge_b <- c_mat_ridge_b[2,2]/sum(c_mat_ridge_b[2,])
Rec_ridge_b
#F1 Score
F1_ridge_b <- 2 * (Prec_ridge_b * Rec_ridge_b)/(Prec_ridge_b + Rec_ridge_b)
F1_ridge_b
#ROC curves
roc_ridge_u <- roc(test$Attrition_Flag ~ as.numeric(ridge_predict_u))
roc_ridge_b <- roc(test$Attrition_Flag ~ as.numeric(ridge_predict_b))
plot(roc_ridge_u, col = "black",print.auc = FALSE, auc.polygon = TRUE,
max.auc.polygon = TRUE, lwd=2)
plot(roc_ridge_b,add = TRUE,col = "blue", print.auc = FALSE, lwd=2)
text(0.3, 0.45, paste("AUC for ridge_u:", round(roc_ridge_u$auc, 3)), col = "black")
text(0.3, 0.38, paste("AUC for ridge_b:", round(roc_ridge_b$auc, 3)), col = "blue")
# Matrix without Attrition_Flag and Avg_Open_To_Buy
train_mat <- data.matrix(train_int[,-c(1)])
test_mat <- data.matrix(test_int[,-c(1)])
lasso_u <- cv.glmnet(train_mat,train$Attrition_Flag, alpha = 1,
family = "binomial", type.measure = "class")
plot(lasso_u)
lambda_lasso_u <- lasso_u$lambda.min
lambda_lasso_u
#Threshold
Threshold <- 0.4
lasso_predict_u <- predict(lasso_u,test_mat,type = "response", s = lambda_lasso_u)
pred_lasso_u <- ifelse(lasso_predict_u >= Threshold , 1,0)
#Confusion matrix
c_mat_lasso_u <- table(test$Attrition_Flag,pred_lasso_u)
c_mat_lasso_u
#Accuracy
mean(pred_lasso_u==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_lasso_u <- c_mat_lasso_u[1,1]/sum(c_mat_lasso_u[1,])
Spec_lasso_u
#Precision / Positive Predicted Value
Prec_lasso_u <- c_mat_lasso_u[2,2]/sum(c_mat_lasso_u[,2])
Prec_lasso_u
#Recall / True Positive Rate / Sensitivity
Rec_lasso_u <- c_mat_lasso_u[2,2]/sum(c_mat_lasso_u[2,])
Rec_lasso_u
#F1 Score
F1_lasso_u <- 2 * (Prec_lasso_u * Rec_lasso_u)/(Prec_lasso_u + Rec_lasso_u)
F1_lasso_u
# Matrix without Attrition_Flag
train_mat_b <- data.matrix(train_bal_int[,-c(1)])
test_mat_b <- data.matrix(test_int[,-c(1)])
lasso_b <- cv.glmnet(train_mat_b,train_bal$Attrition_Flag, alpha = 1,
family = "binomial", type.measure = "class")
plot(lasso_b)
lambda_lasso_b <- lasso_b$lambda.min
lambda_lasso_b
#Threshold
Threshold <- 0.8
lasso_predict_b <- predict(lasso_b,test_mat_b,type = "response", s = lambda_lasso_b)
pred_lasso_b <- ifelse(lasso_predict_b >= Threshold , 1,0)
#Confusion matrix
c_mat_lasso_b <- table(test$Attrition_Flag,pred_lasso_b)
c_mat_lasso_b
#Accuracy
mean(pred_lasso_b==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_lasso_b <- c_mat_lasso_b[1,1]/sum(c_mat_lasso_b[1,])
Spec_lasso_b
#Precision / Positive Predicted Value
Prec_lasso_b <- c_mat_lasso_b[2,2]/sum(c_mat_lasso_b[,2])
Prec_lasso_b
#Recall / True Positive Rate / Sensitivity
Rec_lasso_b <- c_mat_lasso_b[2,2]/sum(c_mat_lasso_b[2,])
Rec_lasso_b
#F1 Score
F1_lasso_b <- 2 * (Prec_lasso_b * Rec_lasso_b)/(Prec_lasso_b + Rec_lasso_b)
F1_lasso_b
#ROC curves
roc_lasso_u <- roc(test$Attrition_Flag ~ as.numeric(lasso_predict_u))
roc_lasso_b <- roc(test$Attrition_Flag ~ as.numeric(lasso_predict_b))
plot(roc_lasso_u, col = "black",print.auc = FALSE, auc.polygon = TRUE,
max.auc.polygon = TRUE, lwd=2)
plot(roc_lasso_b,add = TRUE,col = "blue", print.auc = FALSE, lwd=2)
text(0.3, 0.45, paste("AUC for lasso_u:", round(roc_lasso_u$auc, 3)), col = "black")
text(0.3, 0.38, paste("AUC for lasso_b:", round(roc_lasso_b$auc, 3)), col = "blue")
#Thresholds
Threshold1 <- 0.6
Threshold2 <- 0.7
Threshold3 <- 0.8
lasso_bal_predict_2 <- predict(lasso_b,test_mat_b,type = "response", s = lambda_lasso_b)
pred_1 <- ifelse(lasso_bal_predict_2 >= Threshold1 , 1,0)
pred_2 <- ifelse(lasso_bal_predict_2 >= Threshold2 , 1,0)
pred_3 <- ifelse(lasso_bal_predict_2 >= Threshold3 , 1,0)
#Confusion matrix
c_mat_1 <- table(test$Attrition_Flag,pred_1)
c_mat_2 <- table(test$Attrition_Flag,pred_2)
c_mat_3 <- table(test$Attrition_Flag,pred_3)
c_mat_1
c_mat_2
c_mat_3
#Accuracy
mean(pred_1==test$Attrition_Flag)*100
mean(pred_2==test$Attrition_Flag)*100
mean(pred_3==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_1 <- c_mat_1[1,1]/sum(c_mat_1[1,])
Spec_2 <- c_mat_2[1,1]/sum(c_mat_2[1,])
Spec_3 <- c_mat_3[1,1]/sum(c_mat_3[1,])
Spec_1
Spec_2
Spec_3
#Precision / Positive Predicted Value
Prec_1 <- c_mat_1[2,2]/sum(c_mat_1[,2])
Prec_2 <- c_mat_2[2,2]/sum(c_mat_2[,2])
Prec_3 <- c_mat_3[2,2]/sum(c_mat_3[,2])
Prec_1
Prec_2
Prec_3
#Recall / True Positive Rate / Sensitivity
Rec_1 <- c_mat_1[2,2]/sum(c_mat_1[2,])
Rec_2 <- c_mat_2[2,2]/sum(c_mat_2[2,])
Rec_3 <- c_mat_3[2,2]/sum(c_mat_3[2,])
Rec_1
Rec_2
Rec_3
#F1 Score
F1_1 <- 2 * (Prec_1 * Rec_1)/(Prec_1 + Rec_1)
F1_2 <- 2 * (Prec_2 * Rec_2)/(Prec_2 + Rec_2)
F1_3 <- 2 * (Prec_3 * Rec_3)/(Prec_3 + Rec_3)
F1_1
F1_2
F1_3
c_mat_lasso_u
#Threshold
Threshold <- 0.7
lasso_predict_b <- predict(lasso_b,test_mat_b,type = "response", s = lambda_lasso_b)
pred_lasso_b <- ifelse(lasso_predict_b >= Threshold , 1,0)
#Confusion matrix
c_mat_lasso_b <- table(test$Attrition_Flag,pred_lasso_b)
c_mat_lasso_b
#Threshold
Threshold <- 0.7
lasso_predict_b <- predict(lasso_b,test_mat_b,type = "response", s = lambda_lasso_b)
pred_lasso_b <- ifelse(lasso_predict_b >= Threshold , 1,0)
#Confusion matrix
c_mat_lasso_b <- table(test$Attrition_Flag,pred_lasso_b)
#Accuracy
mean(pred_lasso_b==test$Attrition_Flag)*100
#True Negative Rate / Specificity
Spec_lasso_b <- c_mat_lasso_b[1,1]/sum(c_mat_lasso_b[1,])
Spec_lasso_b
#Precision / Positive Predicted Value
Prec_lasso_b <- c_mat_lasso_b[2,2]/sum(c_mat_lasso_b[,2])
Prec_lasso_b
#Recall / True Positive Rate / Sensitivity
Rec_lasso_b <- c_mat_lasso_b[2,2]/sum(c_mat_lasso_b[2,])
Rec_lasso_b
#F1 Score
F1_lasso_b <- 2 * (Prec_lasso_b * Rec_lasso_b)/(Prec_lasso_b + Rec_lasso_b)
F1_lasso_b
#ROC curves
roc_lasso_u <- roc(test$Attrition_Flag ~ as.numeric(lasso_predict_u))
roc_lasso_b <- roc(test$Attrition_Flag ~ as.numeric(lasso_predict_b))
plot(roc_lasso_u, col = "black",print.auc = FALSE, auc.polygon = TRUE,
max.auc.polygon = TRUE, lwd=2)
plot(roc_lasso_b,add = TRUE,col = "blue", print.auc = FALSE, lwd=2)
text(0.3, 0.45, paste("AUC for lasso_u:", round(roc_lasso_u$auc, 3)), col = "black")
text(0.3, 0.38, paste("AUC for lasso_b:", round(roc_lasso_b$auc, 3)), col = "blue")
F1_i
F1_f
F1_lda_u
F1_qda_u
F1_ridge_u
F1_lasso_u
Rec_i
Rec_f
Rec_lda_u
Rec_qda_u
Rec_ridge_u
Rec_lasso_u
roc_i$auc
roc_f$auc
roc_lda_u$auc
roc_qda_u$auc
roc_ridge_u$auc
roc_lasso_u$auc
F1_i_bal
F1_f_bal
F1_lda_b
F1_qda_b
F1_ridge_b
F1_lasso_b
Rec_i_bal
Rec_f_bal
Rec_lda_b
Rec_qda_b
Rec_ridge_b
Rec_lasso_b
roc_i$auc
roc_f_bal$auc
roc_i_bal$auc
roc_lda_b$auc
roc_qda_b$auc
roc_ridge_b$auc
roc_lasso_b$auc
---
title: "Stat_Markdown"
knitr::opts_chunk$set(echo = TRUE)
```{r}
Grouped.age.hist <- barplot(as.numeric(cleaned_bank_data_withoutNA_quan$age_group), xlab="age_group", ylab="freq",
main="Customer age group distribution", col="green")
library("dplyr")
library("corrplot")
library("caTools")
library("ggpubr")
library("ROSE")
library("correlation")
library("moments") #to calculate skewness
library("olsrr") #to use ols_step_backward_p
library("MASS")
library("knitr")
library("forecast")
library("ggplot2")
library("PCAmixdata")
library("purrr")
library("corpcor")
library("car")
library("e1071")
library("ppcor")
library("pROC")
library("interactions")
library("glmnet")
library("formattable") # for giving a variable dictionary a better look
library("RColorBrewer")# for the visualization colorings
bank_data_origin <- read.csv('~/GitHub/Stats_23_Project/BankChurners.csv')
head(bank_data_origin)
summary(bank_data_origin)
dim(bank_data_origin)
bank_data <- subset(bank_data_origin, select = -c(Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1, Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2))
final_dim <- dim(bank_data)
final_dim
# BRIEF DESCRIPTION OF EACH VARIABLE
var.names <- c("Clientnum", "Attrition_Flag", "Customer_Age", "Gender", "Dependent_count",
"Education_Level", "Marital_Status", "Income_Category", "Card_Category", "Months_on_book",
"Total_Relationship_Count", "Months_Inactive_12_mon", "Contacts_Count_12_mon", "Credit_Limit",
"Total_Revolving_Bal", "Avg_Open_To_Buy", "Total_Amt_Chng_Q4_Q1", "Total_Trans_Amt",
"Total_Trans_Ct", "Total_Ct_Chng_Q4_Q1", "Avg_Utilization_Ratio")
descriptions <- c("refers to the distinct identification numbers assigned to customers, consisting of a unique sequence of 9 digits. The datasets contain a total of 10,127 customers with unique IDs.",
"refers to the current status of customers, indicating whether they are Existing Customers (current customers) or Attrited Customers (churned customers). There are two distinct values for this target/output variable.",
"represents the age of customers, with a range between 27 and 73.",
"is encoded as 'F' for Female and 'M' for Male.",
"represents the number of dependents associated with a customer.",
"represents the educational qualification of a customer. It encompasses seven distinct values: High School, Graduate, Uneducated, College, Post-graduate, Doctorate, and Unknown. The Unknown category includes 1519 customers.",
"represents the marital status of customers, with four unique values: Married, Single, Unknown, and Divorced. The Unknown category includes 749 customers.",
"represents the annual income category of cardholders: Less than 40K, 40K-60K, 60K-80K, 80K-120K, $120+, and Unknown. The Unknown category includes 1112 customers.",
"refers to a product variable that indicates the type of credit card held by customers. It includes four unique values: Blue, Gold, Silver, and Platinum.",
"represents the duration, in months, that an account holder has been a customer at the bank.",
"represents the number of products held by a customer.",
"represents the number of months during which a customer has been inactive in the last 12 months (1 year).",
"represents the number of times a customer has contacted the bank.",
"represents the credit limit on the customer's credit card.",
"represents the total revolving balance on the customer's credit card.",
"represents the average Open to Buy Credit Line for the last 12 months.",
"represents the change in transaction amount from the fourth quarter (Q4) to the first quarter (Q1).",
"represents the total transaction amount in the last 12 months.",
"represents the total transaction count in the last 12 months.",
"represents the change in transaction count from the fourth quarter (Q4) to the first quarter (Q1).",
"represents the average card utilization ratio.")
var.dict <- as.data.frame(descriptions, row.names = var.names, )
formattable(var.dict)
# DATA PREPERATION
#display of the categorical variables
table(bank_data$Attrition_Flag)
table(bank_data$Gender)
table(bank_data$Education_Level)
table(bank_data$Marital_Status)
table(bank_data$Income_Category)
table(bank_data$Card_Category)
#Change Unknown value to NA
bank_data_NA <- data.frame(bank_data)
bank_data_NA[bank_data_NA=='Unknown'] <- NA
#Build a dataset without missing values
bank_data_withoutNA <- na.omit(bank_data_NA)
#We convert categorical variables into numerical
bank_data_withoutNA_quan <- data.frame(bank_data_withoutNA)
#change 'Existing Customer' to 1 and 'Attrited Customer' to 0 and add new column to quantitative
bank_data_withoutNA_quan$Attrition_Flag <- as.numeric(bank_data_withoutNA_quan$Attrition_Flag == "Attrited Customer")
bank_data_withoutNA_quan$Gender <- as.numeric(bank_data_withoutNA_quan$Gender == "F")
bank_data_withoutNA_quan <- bank_data_withoutNA_quan %>% rename("Is_Female" = "Gender")
order_education_level <- list("Uneducated" = 1,
"High School" = 2,
"College" = 3,
"Graduate" = 4,
"Post-Graduate" = 5,
"Doctorate" = 6)
bank_data_withoutNA_quan$Education_Level <- unlist(order_education_level[as.character(bank_data_withoutNA_quan$Education_Level)])
order_Marital_Status <- list("Single" = 1,
"Married" = 2,
"Divorced" = 3)
bank_data_withoutNA_quan$Marital_Status <- unlist(order_Marital_Status[as.character(bank_data_withoutNA_quan$Marital_Status)])
order_Income_Category <- list("Less than $40K" = 1,
"$40K - $60K" = 2,
"$60K - $80K" = 3,
"$80K - $120K" = 4,
"$120K +" = 5)
bank_data_withoutNA_quan$Income_Category <- unlist(order_Income_Category[as.character(bank_data_withoutNA_quan$Income_Category)])
order_Card_Category <- list("Blue" = 1,
"Silver" = 2,
"Gold" = 3,
"Platinum" = 4)
bank_data_withoutNA_quan$Card_Category <- unlist(order_Card_Category[as.character(bank_data_withoutNA_quan$Card_Category)])
#Categorical Value Visualizations
#Bar plots
par(mfrow=c(2,2))
myPalette <- brewer.pal(6, "Set2")
ggplot(bank_data_withoutNA_quan, aes(x = as.factor(Income_Category), fill = factor(Attrition_Flag))) + geom_bar() + labs(fill = "Attrition Flag")
ggplot(bank_data_withoutNA_quan, aes(x = as.factor(Marital_Status), fill = factor(Attrition_Flag))) + geom_bar() + labs(fill = "Attrition Flag")
ggplot(bank_data_withoutNA_quan, aes(x = as.factor(Education_Level), fill = factor(Attrition_Flag))) + geom_bar() + labs(fill = "Attrition Flag")
ggplot(bank_data_withoutNA_quan, aes(x = as.factor(Card_Category), fill = factor(Attrition_Flag))) + geom_bar() + labs(fill = "Attrition Flag")
# Card Category
ggplot(bank_data_withoutNA_quan, aes(x=Months_on_book, y= Credit_Limit, shape = as.factor(Card_Category), color= as.factor(Card_Category)))+
geom_point() + geom_smooth(method=lm, se=FALSE, fullrange=TRUE)
#Numerical columns analysis
attach(bank_data_withoutNA_quan)
cust.age.boxplot <- boxplot(Customer_Age, ylab = "age")
months.onbook.boxplot <- boxplot(Months_on_book, ylab = "months")
reltn.cnt.boxplot <- boxplot(Total_Relationship_Count, ylab = "#")
mnths.inact.boxplot <- boxplot(Months_Inactive_12_mon, ylab = "months")
cntc.cnt.boxplot <- boxplot(Contacts_Count_12_mon, ylab = "#")
credit.limit.boxplot <- boxplot(Credit_Limit, ylab = "Dollars")
ttl.revbal.boxplot <- boxplot(Total_Revolving_Bal, ylab = "Dollars")
avg.opnbuy.boxplot <- boxplot(Avg_Open_To_Buy, ylab = "Dollars")
total.amtchg.boxplot <- boxplot(Total_Amt_Chng_Q4_Q1, ylab = "Dollars")
ttl.transct.boxplot <- boxplot(Total_Trans_Ct, ylab = "#")
total.cntchg.boxplot <- boxplot(Total_Ct_Chng_Q4_Q1, ylab = "Dollars")
avg.utilrate.boxplot <- boxplot(Avg_Utilization_Ratio, ylab = "Ratio")
#Since the outliers in most of the numerical columns can be identifying on whether the customer is going to churn we decided to keep them in the data set
#Extracting Outliers from age and Rescoping the study to only focus on Blue Cards
#using the 1st quartile-1.5*IQR and 3rd quartile+1.5*IQR rule,
#it is seen that customers over the age of 70 are outliers
age.exc.list <- boxplot.stats(bank_data_withoutNA_quan$Customer_Age)$out
#Since most of the data is coming from the Blue cards and there is a visible difference on many parameters among categories, we decided to only focus on blue card category
card.exc.list <- c(2, 3, 4)
cleaned_bank_data_withoutNA_quan <- subset(bank_data_withoutNA_quan,!((Customer_Age %in% age.exc.list)| (Card_Category %in% card.exc.list)))
cleaned_bank_data_withoutNA_quan<- subset(cleaned_bank_data_withoutNA_quan, select = -c(Card_Category))
cleaned_bank_data_withoutNA_quan
# Descriptive Graphs
#histogram
Cust.age.hist <- hist(cleaned_bank_data_withoutNA_quan$Customer_Age, xlab="age", ylab="freq",
main="Customer age distribution", col="orange")
Cust.age.hist
#using the histogram, dividing ages into 4 groups seems satisfying
#Creating age groups
cleaned_bank_data_withoutNA_quan[cleaned_bank_data_withoutNA_quan$Customer_Age <= 34, "age_group"] <- 1
cleaned_bank_data_withoutNA_quan[cleaned_bank_data_withoutNA_quan$Customer_Age > 34 & cleaned_bank_data_withoutNA_quan$Customer_Age <= 44, "age_group"] <- 2
cleaned_bank_data_withoutNA_quan[cleaned_bank_data_withoutNA_quan$Customer_Age > 44 & cleaned_bank_data_withoutNA_quan$Customer_Age <= 54, "age_group"] <- 3
cleaned_bank_data_withoutNA_quan[cleaned_bank_data_withoutNA_quan$Customer_Age > 54, "age_group"] <- 4
#grouped age histogram
Grouped.age.hist <- hist(as.numeric(cleaned_bank_data_withoutNA_quan$age_group), xlab="age_group", ylab="freq", breaks=4,
main="Customer age group distribution", col="green")
# grouped age piechart
age.labels <- c("<=34", "35-44", "45-54", ">=55")
cust.age.piechart <- pie(count(cleaned_bank_data_withoutNA_quan, age_group)$n, border="white", col=myPalette, labels = age.labels)
#Dependent Count
depcount.labels <- c(0, 1, 2, 3, 4, 5)
dependent.count.piechart <- pie(count(cleaned_bank_data_withoutNA_quan, Dependent_count)$n, border="white", col=myPalette, labels = depcount.labels)
#Months inactive
library(yarrr) #to make colors transparent
barplot(table(factor(Months_Inactive_12_mon,levels=min(Months_Inactive_12_mon):max(Months_Inactive_12_mon))), col = yarrr::transparent('red',trans.val = 0.9))
barplot(table(factor(Contacts_Count_12_mon,levels=min(Contacts_Count_12_mon):max(Contacts_Count_12_mon))), col = yarrr::transparent('blue', trans.val = 0.8), add = TRUE)
hist(cleaned_bank_data_withoutNA_quan$Total_Trans_Ct)
int.hist = function(x,ylab="Frequency",...) {
barplot(table(factor(x,levels=min(x):max(x))),space=0,xaxt="n",ylab=ylab,...);axis(1)
}
#Histograms
attach(cleaned_bank_data_withoutNA_quan)
par(mfrow=c(3,2))
hist(Avg_Open_To_Buy)
hist(Total_Trans_Amt)
hist(Avg_Utilization_Ratio)
hist(Months_on_book)
hist(Credit_Limit)
hist(Months_Inactive_12_mon)
#grouped age histogram
par(mfrow=c(1,1))
#Grouped.age.hist <- barplot(as.numeric($age_group), xlab="age_group", ylab="freq",
#                         main="Customer age group distribution", col="green")
cleaned_bank_data_withoutNA_quan %>%
group_by(age_group) %>% summarise(N=n()) %>%
ggplot(aes(x=age_group,y=N,fill=age_group))+
geom_bar(stat = 'age group',color='black')+
scale_y_continuous(labels = scales::comma_format(accuracy = 2))+
geom_text(aes(label=N),vjust=-0.25,fontface='bold')+
theme_bw()+
theme(axis.text = element_text(color='black',face='bold'),
axis.title = element_text(color='black',face='bold'),
legend.text = element_text(color='black',face='bold'),
legend.title = element_text(color='black',face='bold'))
#Grouped.age.hist <- barplot(as.numeric($age_group), xlab="age_group", ylab="freq",
#                         main="Customer age group distribution", col="green")
cleaned_bank_data_withoutNA_quan %>%
group_by(age_group) %>% summarise(N=n()) %>%
ggplot(aes(x=age_group,y=N,fill=age_group))+
geom_bar(stat = 'identity',color='black')+
scale_y_continuous(labels = scales::comma_format(accuracy = 2))+
geom_text(aes(label=N),vjust=-0.25,fontface='bold')+
theme_bw()+
theme(axis.text = element_text(color='black',face='bold'),
axis.title = element_text(color='black',face='bold'),
legend.text = element_text(color='black',face='bold'),
legend.title = element_text(color='black',face='bold'))
hist(Avg_Open_To_Buy, fig.dim = c(4, 3))
fig.dim = c(4, 3)
